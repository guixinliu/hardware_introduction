### A Pluto.jl notebook ###
# v0.19.11

using Markdown
using InteractiveUtils

# â•”â•â•¡ 675e66aa-8aef-11eb-27be-5fe273e33297
# Load packages
begin
    using BenchmarkTools
    using PlutoUI
end

# â•”â•â•¡ 15f5c31a-8aef-11eb-3f19-cf0a4e456e7a
md"""
# æ¯ä¸ªç§‘ç ”å·¥ä½œè€…éƒ½éœ€è¦äº†è§£çš„å…³äºé«˜æ€§èƒ½ä»£ç çš„ç¡¬ä»¶çŸ¥è¯†

**æœ¬æ•™ç¨‹çš„è‹±æ–‡ç‰ˆä½äº https://github.com/jakobnissen/hardware_introduction**

ç°å¦‚ä»Šï¼Œç¼–ç¨‹å·²ç»æˆä¸ºè®¸å¤šç§‘ç ”é¢†åŸŸçš„ä¸€é¡¹åŸºæœ¬æŠ€èƒ½ï¼Œè®¸å¤šç§‘å­¦å®¶éƒ½éœ€è¦ä¸ºä»–ä»¬çš„ç§‘ç ”é¡¹ç›®å†™ä¸€äº›ç‰¹å®šä»£ç ã€‚
ä¸è¿‡ï¼Œå¤§éƒ¨åˆ†ç§‘ç ”å·¥ä½œè€…å…¶å®å¹¶ä¸æ˜¯ç§‘ç­å‡ºèº«çš„ç¨‹åºå‘˜ï¼Œä»–ä»¬ä¹Ÿä»…ä»…åªæ˜¯å› ä¸ºéœ€è¦æ‰å»å­¦ä¹ ç¼–ç¨‹ã€‚
æˆ‘è®¤ä¸ºè‡ªå·±å°±æ˜¯å…¶ä¸­ä¹‹ä¸€ã€‚
è™½ç„¶ä»**è½¯ä»¶**å±‚é¢æ¥è¯´æˆ‘ä»¬å¯èƒ½å·²ç»å¾ˆç†Ÿæ‚‰ç¼–ç¨‹äº†ï¼Œä½†æ˜¯å¯¹äº**ç¡¬ä»¶**æ˜¯å¦‚ä½•å½±å“ä»£ç æ€§èƒ½è¿™ä»¶äº‹æƒ…ï¼Œæˆ‘ä»¬çŸ¥ä¹‹ç”šå°‘ã€‚

æœ¬æ•™ç¨‹æ—¨åœ¨æä¾›ä¸€ä¸ªå…³äºç°ä»£ç¡¬ä»¶ç‰¹æ€§çš„**ç®€æ˜**æ¦‚è¿°ï¼Œä»è€Œè®©åƒæˆ‘è¿™æ ·çš„éç§‘ç­ç¨‹åºå‘˜ä¹ŸçŸ¥é“å¦‚ä½•å†™å‡ºé«˜æ€§èƒ½çš„ä»£ç ã€‚
è¿™ä¸ªæ•™ç¨‹çš„å†…å®¹æºäºæˆ‘å¯¹è¿‡äºå‡ å¹´ç¼–ç¨‹ç»éªŒçš„æ€»ç»“ã€‚
æœ¬æ•™ç¨‹å°†ä½¿ç”¨ Juliaï¼Œ å› ä¸ºå®ƒèƒ½å¤Ÿä½¿ç”¨é«˜çº§äº¤äº’å¼è¯­è¨€è½»æ¾åœ°æ¼”ç¤ºè¿™äº›æ¥è‡ªäºç¡¬ä»¶åº•å±‚çš„å½±å“å› ç´ ã€‚

## ä¸ä¼šè¦†ç›–çš„å†…å®¹
#### å…³äº Julia ç¼–ç¨‹è¯­è¨€çš„æŒ‡å— 
ä¸ºäº†ç¼–å†™å¿«é€Ÿä»£ç ï¼Œä½ å¿…é¡»é¦–å…ˆäº†è§£ä½ çš„ç¼–ç¨‹è¯­è¨€åŠå…¶ç‰¹æ€§ã€‚ä½†è¿™**ä¸æ˜¯**å…³äº Julia ç¼–ç¨‹è¯­è¨€çš„æŒ‡å—ã€‚æˆ‘å»ºè®®é˜…è¯» Julia æ–‡æ¡£ä¸­çš„[æ€§èƒ½å»ºè®®](https://docs.juliacn.com/latest/manual/performance-tips/) èŠ‚ã€‚

#### å…³äºç‰¹å®šæ•°æ®ç»“æ„æˆ–ç®—æ³•çš„è¯´æ˜
ä¸ºäº†åŠ é€Ÿä»£ç ï¼Œé™¤äº†è¦å¼„æ˜ç™½ç¼–ç¨‹è¯­è¨€ï¼Œä½ ä¹Ÿå¿…é¡»ç†è§£ä½ è‡ªå·±çš„ä»£ç ã€‚ä½ å¿…é¡»äº†è§£å¤§ O è®°å·ï¼Œä¸ºä»€ä¹ˆä¸€äº›ç®—æ³•æ¯”å…¶ä»–ç®—æ³•å¿«, ä»¥åŠä¸åŒæ•°æ®ç»“æ„å†…éƒ¨å¦‚ä½•ç»„ç»‡ã€‚è‹¥æ˜¯ä¸çŸ¥é“**ä»€ä¹ˆæ˜¯`Array`**ï¼Œåˆæ€ä¹ˆèƒ½å¤Ÿä½¿ç”¨æ•°ç»„ä¼˜åŒ–ä»£ç ï¼Ÿ

è¿™åŒæ ·è¶…å‡ºäº†æœ¬æ–‡çš„èŒƒå›´ã€‚ç„¶è€Œï¼Œæˆ‘æƒ³è¯´çš„æ˜¯ï¼Œä¸€ä¸ªç¼–ç¨‹é€‰æ‰‹è‡³å°‘åº”è¯¥äº†è§£ï¼š

* äºŒè¿›åˆ¶æ•´æ•°åœ¨å†…å­˜ä¸­çš„è¡¨ç¤ºæ–¹å¼
* æµ®ç‚¹æ•°åœ¨å†…å­˜ä¸­çš„è¡¨ç¤ºæ–¹å¼ -- å­¦ä¹ è¿™ç‚¹ä¹Ÿæ˜¯å¿…è¦çš„ï¼Œå› ä¸ºè¿™æœ‰åŠ©äºç†è§£æµ®ç‚¹è¿ç®—çš„è®¡ç®—è¯¯å·®ï¼Œè€Œæµ®ç‚¹è¿ç®—æ˜¯ç§‘å­¦è®¡ç®—ä¸­ä¸å¯æˆ–ç¼ºçš„éƒ¨åˆ†
* `String` çš„å†…å­˜å¸ƒå±€ï¼ŒåŒ…æ‹¬ ASCII å’Œ UTF-8 ç¼–ç 
* å…³äº`Array` ç»“æ„åŒ–çš„åŸºæœ¬çŸ¥è¯†ï¼Œä»¥åŠç”±æ•°æ„æˆçš„ç¨ å¯†æ•°ç»„ä¸å¯¹è±¡å¼•ç”¨æ•°ç»„ä¹‹é—´çš„åŒºåˆ«
* å“ˆå¸Œè¡¨ï¼ˆå¦‚å­—å…¸ `Dict` å’Œé›†åˆ `Set`ï¼‰èƒŒåçš„å·¥ä½œåŸç†

æ­¤å¤–ï¼Œæˆ‘è¿˜å»ºè®®ç†Ÿæ‚‰ï¼š

* å †ï¼ˆHeapï¼‰
* åŒç«¯é˜Ÿåˆ—ï¼ˆDequeï¼‰
* å…ƒç»„ï¼ˆTupleï¼‰

#### è¿™ä¸æ˜¯å…³äºä»£ç åŸºå‡†æµ‹è¯•çš„æ•™ç¨‹
**å®é™…**ç¼–å†™é«˜æ€§èƒ½ä»£ç æ—¶ï¼Œæµ‹è¯•ä»£ç æŸ¥æ‰¾ç“¶é¢ˆæ˜¯éå¸¸æœ‰å¿…è¦çš„ï¼Œå³æ‰¾å‡ºæœºå™¨æ¶ˆè€—å¤§å¤šæ•°æ—¶é—´çš„åœ°æ–¹ã€‚é€šå¸¸å¿…é¡»éœ€è¦å¯¹ä¸åŒçš„å‡½æ•°å’Œæ–¹æ³•è¿›è¡ŒåŸºå‡†æµ‹è¯•ï¼Œæ‰èƒ½æ‰¾åˆ°æœ€å¿«å®è·µã€‚Juliaï¼ˆä»¥åŠå…¶ä»–è¯­è¨€ï¼‰ä¸ºæ­¤æä¾›äº†å·¥å…·ï¼Œä½†æ­¤å¤„ä¸åšä»‹ç»ã€‚
"""

# â•”â•â•¡ 5dd2329a-8aef-11eb-23a9-7f3c325bcf74
md"""## notebook çš„åˆå§‹åŒ–è®¾ç½®

å¦‚æœä½ æ²¡æœ‰å®‰è£…å¦‚ä¸‹çš„è½¯ä»¶åŒ…ï¼Œè¯·å–æ¶ˆæ³¨é‡Šä¸‹é¢å‡ è¡Œï¼Œå¹¶è¿è¡Œå®ƒä»¬ï¼š
"""

# â•”â•â•¡ 7490def0-8aef-11eb-19ce-4b11ce5a9328
# begin
#     using Pkg
#     Pkg.add(["BenchmarkTools", "PlutoUI"])
# end

# â•”â•â•¡ 800d827e-8c20-11eb-136a-97a622a7c1e6
TableOfContents()

# â•”â•â•¡ 9a24985a-8aef-11eb-104a-bd9abf0adc6d
md"""
## è®¡ç®—æœºç¡¬ä»¶çš„åŸºæœ¬ç»“æ„

ç°åœ¨ï¼Œæˆ‘ä»¬å°†ä»ä¸€ä¸ªè®¡ç®—æœºä½“ç³»çš„ç®€åŒ–æ¨¡å‹å¼€å§‹ã€‚åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘å°†åœ¨åç»­ç›¸å…³ç« èŠ‚æ—¶å¢åŠ æ›´å¤šæ¨¡å‹ç»†èŠ‚ã€‚

$$[CPU] â†” [RAM] â†” [DISK]$$

ä¸Šå›¾ä¸­çš„ç®­å¤´æŒ‡ç¤ºäº†æ•°æ®æµçš„æ–¹å‘ã€‚æ­¤å›¾å±•ç¤ºäº†è®¡ç®—æœºçš„ä¸‰ä¸ªé‡è¦ç»„æˆéƒ¨åˆ†ï¼š

* ä¸­å¤®å¤„ç†å™¨ï¼ˆCPUï¼‰æ˜¯ä¸€ä¸ªé‚®ç¥¨å¤§å°çš„èŠ¯ç‰‡ã€‚å®ƒæ˜¯è®¡ç®—æœºçš„å¤§è„‘ï¼Œå³è¿›è¡Œè¿ç®—çš„åœ°æ–¹ã€‚
* éšæœºå­˜å–å­˜å‚¨å™¨ï¼ˆRAMï¼Œæˆ–ç®€ç§°â€œå†…å­˜â€ï¼‰æ˜¯è®¡ç®—æœºçš„çŸ­æœŸå­˜å‚¨å™¨ã€‚è¯¥å­˜å‚¨å™¨éœ€è¦ç”µæºæ¥ç»´æŒï¼Œè€Œä¸”å½“ç”µè„‘å…³æœºæ—¶ä¼šé—å¤±æ•°æ®ã€‚RAM ä¸´æ—¶åœ°å­˜å‚¨äº†åœ¨ CPU å’Œç¡¬ç›˜ä¹‹é—´ä¼ è¾“çš„æ•°æ®ã€‚â€œåŠ è½½â€å„ç§åº”ç”¨ç¨‹åºå’Œæ“ä½œç³»ç»Ÿæ‰€æ¶ˆè€—çš„å¤§éƒ¨åˆ†æ—¶é—´éƒ½æ˜¯ç”¨æ¥å°†æ•°æ®ä»ç¡¬ç›˜è½¬ç§»åˆ° RAMï¼Œå¹¶åœ¨RAMè§£å‹æ•°æ®ã€‚å…¸å‹çš„ä¸ªäººæ¶ˆè´¹çº§ç¬”è®°æœ¬ç”µè„‘çš„ RAM å®¹é‡çº¦ä¸º$10^{11}$ æ¯”ç‰¹ã€‚
* ç¡¬ç›˜æ˜¯å¤§å®¹é‡å­˜å‚¨å•å…ƒã€‚è¿™äº›ç¡¬ç›˜ä¸Šçš„æ•°æ®åœ¨æ–­å¼€ç”µæºåä¾ç„¶å­˜åœ¨ï¼Œå› æ­¤å®ƒæ¶µç›–äº†è®¡ç®—æœºçš„é•¿æœŸå­˜å‚¨ã€‚æ¯GBçš„ç¡¬ç›˜æ¯” RAM ä¾¿å®œå¾ˆå¤šï¼Œä¸ªäººæ¶ˆè´¹çº§ç”µè„‘çš„ç¡¬ç›˜å®¹é‡çº¦ä¸º $10^{13}$ æ¯”ç‰¹ã€‚
"""

# â•”â•â•¡ a2fad250-8aef-11eb-200f-e5f8caa57a67
md"""
## é¿å…é¢‘ç¹è®¿é—®ç¡¬ç›˜
åœ¨è®¨è®ºè½¯ä»¶æ€§èƒ½æ—¶ï¼ŒåŒºåˆ† **ååé‡** å’Œ **å»¶è¿Ÿ** å¾ˆæœ‰ç”¨ã€‚å»¶è¿Ÿæ˜¯æŒ‡äº‹ä»¶å¼€å§‹åˆ°å®Œæˆæ‰€èŠ±è´¹çš„æ—¶é—´ã€‚ååé‡æ˜¯æŒ‡åœ¨ä¸€å®šæ—¶é—´å†…èƒ½å¤Ÿå®Œæˆå¤šå°‘å·¥ä½œé‡çš„æŒ‡æ ‡ã€‚

ä»è¡¨é¢æ¥çœ‹ï¼Œå»¶è¿Ÿå’Œååé‡ä¹‹é—´çš„å…³ç³»çœ‹èµ·æ¥å¾ˆæ˜æ˜¾ï¼šå¦‚æœä¸€ä¸ªæ“ä½œéœ€è¦è¿›è¡Œ $N$ ç§’çš„è®¡ç®—ï¼Œé‚£ä¹ˆæ¯ç§’åªèƒ½æ‰§è¡Œ$1/N$ä¸ªæ“ä½œã€‚æ‰€ä»¥ä½ ä¼šæœ´ç´ åœ°è®¤ä¸ºï¼š

$$ååé‡ = \frac{1}{å»¶è¿Ÿ}$$

å®é™…ä¸Šå¹¶ä¸æ˜¯è¿™ä¹ˆç®€å•ã€‚ä¾‹å¦‚ï¼Œè®¾æƒ³å¦‚ä¸‹çš„æ“ä½œï¼šéœ€è¦ 1 ç§’ç”¨äºåœ¨å¼€å§‹å‰é¢„çƒ­ï¼Œä½†é¢„çƒ­åæ¯æ¬¡æ“ä½œåªéœ€ 0.1 ç§’ã€‚è¯¥æ“ä½œçš„ å»¶è¿Ÿ æ˜¯ 1.1 ç§’ï¼Œä½†ä»–é¢„çƒ­åçš„ååé‡æ˜¯ 10 æ“ä½œ/ç§’ã€‚

æˆ–è€…ï¼Œè®¾æƒ³å¦‚ä¸‹çš„æƒ…å½¢ï¼šéœ€è¦ 1 ç§’çš„ å»¶è¿Ÿï¼Œä½†æ˜¯èƒ½å¤ŸåŒæ—¶æ‰§è¡Œ8ä¸ªæ“ä½œã€‚å½“æ‰¹é‡è¿è¡Œæ—¶ï¼Œè¿™äº›æ“ä½œçš„ååé‡ä¸º 8 æ“ä½œ/ç§’ã€‚

ç¡¬ç›˜è¯»å–æ˜¯ä¸€ä¸ªå€¼å¾—åŒºåˆ†å»¶è¿Ÿå’Œååé‡çš„æ—¶æœºã€‚å¤§å¤šæ•°ç°ä»£ç”µè„‘ä½¿ç”¨çš„ç¡¬ç›˜ç±»å‹ä¸º**å›ºæ€ç¡¬ç›˜ï¼ˆSSDï¼‰**ã€‚ç²—ç•¥åœ°è®²ï¼Œç›®å‰ï¼ˆ2021å¹´ï¼‰ SSD çš„å»¶è¿Ÿçº¦ä¸º 100 Âµsï¼ŒåŒæ—¶è¯»/å†™çš„ååé‡è¿œè¿œè¶…è¿‡ 1 GB/sã€‚å¦ä¸€ç§ç›¸å¯¹è¾ƒæ—§æˆ–è€…è¯´å»‰ä»·çš„å¤§å®¹é‡ç¡¬ç›˜ç±»å‹æ˜¯ **æœºæ¢°ç¡¬ç›˜ï¼ˆHDDï¼‰**ã€‚ç›¸æ¯”äºSSDï¼Œå®ƒä»¬çš„å»¶è¿Ÿè¦æ…¢ 100 å€ï¼Œå¤§çº¦ 10 msï¼ŒåŒæ—¶ååé‡ä¹Ÿå° 10 å€ï¼Œçº¦ä¸º 100 MB/sã€‚

ç›¸æ¯”äºRAM 100 ns ä»¥ä¸‹çš„å»¶è¿Ÿï¼Œå³ä½¿æ˜¯æœ€æ–°æœ€å¿«çš„ SSDï¼Œå…¶å»¶è¿Ÿä¹Ÿæ¯” RAM æ…¢ä¸Šæ•°åƒå€ã€‚ æ¯ä¸€æ¬¡è¯»æˆ–å†™æ“ä½œéƒ½ä¼šè§¦å‘ç¡¬ç›˜å»¶è¿Ÿã€‚å› æ­¤ï¼Œä¸ºäº†ç¼–å†™é«˜æ€§èƒ½ä»£ç ï¼Œå¿…é¡»ä¸æƒœä¸€åˆ‡ä»£ä»·æ¥é¿å…é‡å¤çš„ç¡¬ç›˜è¯»å†™ã€‚

ä»¥ä¸‹ç¤ºä¾‹ç”¨äºè¯´æ˜ å»¶è¿Ÿ çš„å·®å¼‚ï¼šç¬¬ä¸€ä¸ªå‡½æ•°ä¼šæ‰“å¼€ä¸€ä¸ªæ–‡ä»¶ï¼Œè®¿é—®æ–‡ä»¶çš„ä¸€ä¸ªå­—èŠ‚ï¼Œæœ€åå…³é—­æ–‡ä»¶ã€‚ç¬¬äºŒä¸ªå‡½æ•°åˆ™ä¼šéšæœºè®¿é—® RAM ä¸­çš„ 1,000,000 ä¸ªæ•´æ•°ã€‚
"""

# â•”â•â•¡ cdde6fe8-8aef-11eb-0a3c-77e28f7a2c09
md"""
å¯¹æ–‡ä»¶è®¿é—®çš„åŸºå‡†æµ‹è¯•ä¼šæ˜¾å¾—æœ‰ç‚¹ç»•ã€‚å› ä¸ºåœ¨ Julia ä¸­**ç¬¬ä¸€æ¬¡**æ‰§è¡Œå‡½æ•°æ—¶ä¼šåŒ…å«ç¨‹åºçš„ç¼–è¯‘æ—¶é—´ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸€èˆ¬ä¼šç”¨ç¬¬äºŒæ¬¡æ‰§è¡Œçš„æ—¶é—´ä½œä¸ºç»“æœã€‚
ç„¶è€Œï¼Œåœ¨**ç¬¬äºŒæ¬¡**æ‰§è¡Œå‡½æ•°æ—¶ï¼Œè™½ç„¶ä¸éœ€è¦å†ç¼–è¯‘å‡½æ•°å°±å¯ä»¥æ‰§è¡Œï¼Œä½†ç”±äº**ç¬¬ä¸€æ¬¡**æ‰§è¡Œæ—¶æ“ä½œç³»ç»Ÿå·²ç»ç¼“å­˜äº†è¯¥æ–‡ä»¶ï¼Œæ‰€ä»¥**ç¬¬äºŒæ¬¡**æ‰§è¡Œæ—¶ä¼šç›´æ¥è¿”å›ç»“æœã€‚æ¢å¥è¯è¯´ï¼Œ**ç¬¬äºŒæ¬¡**
æ‰§è¡Œå‡½æ•°æµ‹è¯•çš„å®é™…ä¸Šæ˜¯ç¼“å­˜(RAM)çš„å»¶è¿Ÿè€Œä¸æ˜¯ç¡¬ç›˜çš„å»¶è¿Ÿã€‚
ä¸ºäº†æ­£ç¡®æµ‹é‡ç¡¬ç›˜çš„è¯»å†™å»¶è¿Ÿï¼Œæˆ‘ä»¬éœ€è¦å…ˆå°†å‡½æ•°è¿è¡Œä¸€æ¬¡æ¥è§¦å‘ç¼–è¯‘ï¼Œç„¶åå†å»è¯»å–å¦ä¸€ä¸ªæœ€è¿‘æ²¡æœ‰æ‰“å¼€è¿‡çš„æ–‡ä»¶ã€‚
å› æ­¤ï¼Œäº‹å®ä¸Šåº”è¯¥æ›´æ–°ä¸€ä¸‹æˆ‘ä»¬çš„è®¡ç®—æœºä½“ç³»å›¾ï¼š

$$[CPU] â†” [RAM] â†” [ç¡¬ç›˜ç¼“å­˜] â†” [ç¡¬ç›˜]$$

åœ¨æˆ‘çš„ç”µè„‘ä¸Šï¼Œè®¿é—®æ–‡ä»¶çš„ä¸€ä¸ªå­—èŠ‚ï¼ˆåŒ…æ‹¬æ‰“å¼€å’Œå…³é—­æ–‡ä»¶ï¼‰è¦èŠ±è´¹ 500 Âµsï¼Œè€Œè®¿é—®å†…å­˜ä¸­çš„ 1,000,000 ä¸ªæ•´æ•°èŠ±è´¹ 200 æ¯«ç§’ã€‚æ‰€ä»¥ç¡¬ç›˜å»¶è¿Ÿå¤§çº¦æ˜¯ RAM å»¶è¿Ÿçš„ 2500 å€ã€‚å› æ­¤ï¼Œé«˜æ€§èƒ½è®¡ç®—**å¿…é¡»**é¿å…é‡å¤è®¿é—®æ–‡ä»¶ã€‚

å‡ å¹´å‰ï¼Œ SSD è¿˜ä¸å¸¸è§ï¼Œå¹¶ä¸” HDD çš„ååé‡ä¹Ÿè¦æ¯”ä»Šå¤©å°ã€‚å› æ­¤ï¼Œæ—§æ–‡æœ¬é€šå¸¸ä¼šè­¦å‘Šäººä»¬ï¼Œç”±äºé«˜ååé‡æˆæœ¬ï¼Œä¸€ç‚¹ä¹Ÿä¸è¦è®©ä½ çš„ç¨‹åºä¾èµ–ç¡¬ç›˜ã€‚ä½†æ­¤å»ºè®®åœ¨ä»Šå¤©å·²ç»è¿‡æ—¶äº†ï¼Œå› ä¸ºå¤§å¤šæ•°ç¨‹åºéƒ½ä¸èƒ½è¾¾åˆ°ä½ä»·ä¸”ç°ä»£çš„ SSD çš„ 1 GB/s ååé‡ç“¶é¢ˆã€‚æ­¤å»ºè®®åœ¨ä»Šå¤©åªä»é€‚ç”¨äºé‚£äº›**é¢‘ç¹**è¿›è¡Œç¡¬ç›˜è¯»å†™çš„ç¨‹åºï¼Œè¿™ä¼šç§¯ç´¯å‡ºé«˜**å»¶è¿Ÿ**ã€‚åœ¨è¿™äº›æƒ…å†µä¸‹ï¼Œä½ ç¡®å®åº”è¯¥å°†æ•°æ®ä¿å­˜åœ¨RAM ä¸­ã€‚

å¦‚æœä½ è¯•å›¾æ¯æ¬¡å¾€ä¸€ä¸ªå¤§æ–‡ä»¶é‡Œåªè¯»å†™ä¸€å°éƒ¨åˆ†æ•°æ®ï¼Œæ¯”å¦‚è¯´æ¯æ¬¡è¯»å†™ 1 Byteï¼Œé‚£ä¹ˆä½ å°±ä¼šè§¦å‘æœ€å·®çš„è¯»å†™æ€§èƒ½äº†ã€‚
åœ¨è¿™ç§æƒ…å†µä¸‹ä¸ºäº†æ”¹å–„æ€§èƒ½ï¼Œä¸€èˆ¬ä¼šæ„é€ ä¸€ä¸ªæ–‡ä»¶ç¼“å†²åŒºæ¥é¿å…å¤§é‡çš„è¯»å†™æ“ä½œã€‚
ç›¸æ¯”äºæ¯æ¬¡åªè¯»å†™ 1 Byte çš„å¾ˆå°‘çš„æ•°æ®ï¼Œå€ŸåŠ©ç¼“å†²åŒºæˆ‘ä»¬å¯ä»¥æ¯æ¬¡ä¼šè¯»å–ä¸€å¤§å—çš„è¿ç»­æ•°æ®åˆ°å†…å­˜ä¸­ï¼ˆæ— è®ºæ˜¯å¦çœŸçš„éœ€è¦è¿™ä¹ˆå¤šï¼‰ã€‚
è¿™æ ·ä¸€æ¥ï¼Œæ¯æ¬¡è¿›è¡Œè¯»å–çš„æ—¶å€™ï¼Œæˆ‘ä»¬éƒ½å¯ä»¥å…ˆæ‰‹åŠ¨æ£€æŸ¥ä¸€æ¬¡æ•°æ®æ˜¯å¦åœ¨ç¼“å†²åŒºä¸­ï¼Œå› ä¸ºå¦‚æœåœ¨çš„è¯ï¼Œå°±ä¸éœ€è¦å†è¯»å–ç¡¬ç›˜æ•°æ®äº†ã€‚
è¿™ç§æ–¹æ³•å¯ä»¥å°†ç¡¬ç›˜çš„å»¶è¿Ÿå½±å“é™åˆ°æœ€ä½ã€‚
æ“ä½œç³»ç»Ÿå’Œç¼–ç¨‹è¯­è¨€éƒ½ä¼šè‡ªåŠ¨åˆ©ç”¨ç¼“å­˜ï¼Œä½†æ˜¯æœ‰æ—¶å€™[æ‰‹åŠ¨æ„é€ æ–‡ä»¶ç¼“å†²åŒºä¾ç„¶æ˜¯å¿…è¦çš„](https://github.com/JuliaLang/julia/issues/34195)ã€‚

"""

# â•”â•â•¡ f58d428c-8aef-11eb-3127-89d729e23823
md"""
## é¿å…ç¼“å­˜æœªå‘½ä¸­
RAM æ¯”ç¡¬ç›˜å¿«ï¼Œè€Œ CPU åˆæ¯” RAM å¿«ã€‚CPU æ»´ç­”ç±»ä¼¼äºæ—¶é’Ÿï¼Œé€Ÿåº¦çº¦ä¸º 3 GHzï¼Œå³æ¯ç§’æ»´ç­”30äº¿æ¬¡ã€‚
CPU æ—¶é’Ÿçš„ä¸€æ¬¡**æ»´ç­”**è¢«ç§°ä¸º**æ—¶é’Ÿå‘¨æœŸ**ã€‚
è™½ç„¶è¿™åšäº†ç®€åŒ–ï¼Œä½†æ˜¯ä½ å¯ä»¥æƒ³è±¡ï¼Œåœ¨æ¯ä¸ªå‘¨æœŸå†…ï¼ŒCPUéƒ½ä¼šæ‰§è¡Œä¸€æ¡ç®€å•çš„**æŒ‡ä»¤**ï¼Œè¯¥æŒ‡ä»¤æ‰§è¡Œä¸€æ¬¡å¯¹å°å—æ•°æ®çš„æ“ä½œã€‚
æ—¶é’Ÿé€Ÿåº¦å¯ä»¥ä½œä¸ºè®¡ç®—æœºä¸­å…¶ä»–è®¡æ—¶å™¨çš„å‚è€ƒã€‚
äº†è§£æ—¶é’Ÿå‘¨æœŸåˆ°åº•æœ‰å¤šå¿«æ˜¯å¾ˆå€¼å¾—çš„ï¼šå…‰åœ¨ä¸€ä¸ªæ—¶é’Ÿå‘¨æœŸå†…åªå‰è¿› 10 cmã€‚
åœ¨è®¾è®¡ç°ä»£ CPU æ—¶ä¸€ä¸ªé‡è¦çš„é™åˆ¶å› ç´ å°±æ˜¯çº¿è·¯å»¶è¿Ÿï¼Œå³ç”µå­åœ¨ CPU å†…éƒ¨çº¿è·¯ä¼ è¾“æ‰€èŠ±çš„æ—¶é—´ã€‚è¿™æ°æ°æ˜¯å› ä¸º CPU è¿ç®—çš„å¤ªå¿«äº†ã€‚

åœ¨è¯¥å°ºåº¦ä¸Šï¼Œä» RAM ä¸­è¯»å–æ•°æ®éœ€è¦èŠ±è´¹ 500 ä¸ªæ—¶é’Ÿå‘¨æœŸã€‚
é€šè¿‡å°†æ•°æ®æ‹·è´åˆ° RAM å¯ä»¥å‡ç¼“ç¡¬ç›˜å»¶è¿Ÿã€‚ä¸ä¹‹ç±»ä¼¼ï¼ŒRAM ä¸Šçš„æ•°æ®ä¹Ÿå¯ä»¥æ‹·è´åˆ° CPU èŠ¯ç‰‡ä¸Šçš„ä¸€å°å—å†…å­˜ï¼Œç§°ä½œ**ç¼“å­˜ï¼ˆcacheï¼‰**ã€‚
ç¼“å­˜æ¯”å†…å­˜æ›´å¿«çš„åŸå› æœ‰ä¸¤ç‚¹ï¼šä¸€æ–¹é¢åœ¨äºç¼“å­˜æœ¬èº«ä½äº CPU å†…éƒ¨å› æ­¤çº¿è·¯å»¶è¿Ÿæ˜¯å¾ˆä½çš„ï¼Œå¦ä¸€æ–¹é¢åœ¨äº CPU ç¼“å­˜ä¸€èˆ¬é‡‡ç”¨é™æ€ RAM è¿™ç§æ›´å¿«çš„å­˜å‚¨æ–¹æ¡ˆï¼Œè€Œä¸æ˜¯ä¸»æµå†…å­˜ä¸­æ‰€é‡‡ç”¨çš„ä¾¿å®œçš„åŠ¨æ€ RAM çš„æ–¹æ¡ˆã€‚
å› ä¸ºç¼“å­˜å¿…é¡»ä½äº CPU ä¸Šæ‰€å¸¦æ¥çš„å°ºå¯¸é™åˆ¶ï¼Œä»¥åŠç”±äºæ›´åŠ æ˜‚è´µçš„ç”Ÿäº§æˆæœ¬ï¼Œæ‰€ä»¥ç»å…¸ CPU ç¼“å­˜å¤§çº¦ä»…åŒ…å«  $10^8$ æ¯”ç‰¹ï¼Œ è¿™ä»…æ˜¯ RAM å®¹é‡çš„ 1/1000ã€‚
å®é™…ä¸Šï¼ŒCPU ç¼“å­˜ç”±å¤šä¸ªä¸åŒæ€§èƒ½å’Œå®¹é‡çš„å±‚çº§ç»„æˆå¤šçº§ç¼“å­˜ï¼Œä½†åœ¨è¿™é‡Œæˆ‘ä»¬ç®€å•åœ°å°†å®ƒä»¬çœ‹ä½œä¸€ä¸ªæ•´ä½“ï¼Œå¹¶ç»Ÿç§°ä¸º **CPU ç¼“å­˜**ã€‚

$$[CPU] â†” [CPU ç¼“å­˜] â†” [RAM] â†” [ç¡¬ç›˜ç¼“å­˜] â†” [ç¡¬ç›˜]$$

å½“ CPU ä» RAM è¯·æ±‚ä¸€æ®µæ•°æ®æ—¶ï¼Œæ¯”å¦‚ä¸€ä¸ªå­—èŠ‚ï¼Œä¼šé¦–å…ˆæ£€æŸ¥æ•°æ®æ‰€å¤„çš„å†…å­˜æ˜¯å¦å·²ç»åœ¨ CPU ç¼“å­˜ä¸­ã€‚
å¦‚æœæ˜¯ï¼Œé‚£ä¹ˆå°†ä» CPU ç¼“å­˜è¯»å–ã€‚è¿™ç›¸æ¯”ä» RAM è®¿é—®æ›´å¿«ï¼Œé€šå¸¸ä»…éœ€è¦å‡ ä¸ªæ—¶é’Ÿå‘¨æœŸã€‚
å¦‚æœå¦ï¼Œé‚£ä¹ˆå°†å¾—åˆ°**ç¼“å­˜æœªå‘½ä¸­** (cache miss)ï¼Œä½ çš„ç¨‹åºä¼šç­‰å¾…çº¦ 100 ns ç›´åˆ°è®¡ç®—æœºå°†æ•°æ®ä» RAM æ‹·è´åˆ° CPU ç¼“å­˜ã€‚

é™¤äº†éå¸¸ä½å±‚çº§çš„è¯­è¨€å¤–ï¼Œæ‰‹åŠ¨ç®¡ç† CPU ç¼“å­˜æ˜¯ä¸å¯èƒ½çš„ã€‚ç›¸ååœ°ï¼Œæ‚¨å¿…é¡»ç¡®ä¿æœ‰æ•ˆä½¿ç”¨ç¼“å­˜ã€‚

é¦–å…ˆï¼Œä½ äº‰å–ä½¿ç”¨å°½å¯èƒ½å°çš„å†…å­˜ã€‚ä½¿ç”¨çš„å†…å­˜è¶Šå°ï¼Œå½“ CPU éœ€è¦æ•°æ®æ—¶ï¼Œå®ƒå°±è¶Šæœ‰å¯èƒ½åœ¨ç¼“å­˜ä¸Šã€‚ 
è¯·è®°ä½ï¼Œåœ¨ä¸€æ¬¡ç¼“å­˜æœªå‘½ä¸­æ‰€æµªè´¹çš„æ—¶é—´å†…ï¼ŒCPU å¯ä»¥æ‰§è¡Œçº¦ 500 æ¬¡å°æ“ä½œã€‚

ç¼“å­˜çš„æœ‰æ•ˆä½¿ç”¨æœ€ç»ˆä½“ç°åœ¨ **å±€éƒ¨æ€§** è¿™ä¸ªæ¦‚å¿µä¸Šï¼Œåˆ†åˆ«æ˜¯æ—¶é—´ä¸Šå’Œç©ºé—´ä¸Šçš„å±€éƒ¨æ€§ï¼š
* **æ—¶é—´å±€éƒ¨æ€§** æŒ‡çš„æ˜¯ä½ ä¹‹å‰è¯»å–è¿‡çš„æ•°æ®å¾ˆå¯èƒ½å·²ç»å­˜åœ¨ç¼“å­˜ä¸Šäº†ã€‚å› æ­¤ï¼Œå¦‚æœéœ€è¦åå¤è®¿é—®åŒä¸€å—å†…å­˜æ•°æ®ï¼Œè¯·ç¡®ä¿è¿™äº›è®¿é—®æ“ä½œåœ¨å°½å¯èƒ½çŸ­çš„æ—¶é—´å†…è¿›è¡Œã€‚
* **ç©ºé—´å±€éƒ¨æ€§** æŒ‡çš„æ˜¯ä½ åº”è¯¥è¯»å–å°½å¯èƒ½ç›¸é‚»ä½ç½®çš„å†…å­˜æ•°æ®ã€‚
  å› ä¸º CPU ä¸ä»…ä»…åªæ˜¯æŠŠä½ éœ€è¦çš„é‚£äº›å­—èŠ‚æ”¾åˆ° CPU ç¼“å­˜ä¸­ï¼Œå®ƒå®é™…ä¸Šä¼šå°†æ›´å¤§çš„ä¸€æ®µæ•°æ®å­˜åˆ° CPU ç¼“å­˜ä¸­ã€‚
  è¿™æ ·ä¸€æ®µæ•°æ®è¢«ç§°ä¸º **ç¼“å­˜çº¿** (cache line)ï¼Œå®ƒä»¬å¤§æ¦‚æ˜¯ 512 ä¸ªè¿ç»­æ¯”ç‰¹ï¼Œä¾å…·ä½“çš„ CPU å‹å·è€Œå®šã€‚

ä¸ºäº†è¯´æ˜ä¸Šè¿°å·®åˆ«ï¼Œè®©æˆ‘ä»¬æ¯”è¾ƒä¸¤ç§æƒ…å†µä¸‹éšæœºè¯»å–å‡½æ•° `random_access` çš„æ€§èƒ½ï¼šç¬¬ä¸€ç§è®¿é—® 8 KiB å¤§å°çš„çŸ­å‘é‡ï¼Œç¬¬äºŒç§è®¿é—® 16 MiB å¤§å°çš„é•¿å‘é‡ã€‚
åœ¨å‰è€…çŸ­å‘é‡çš„æƒ…å†µä¸‹ï¼Œå› ä¸ºæ•°æ®æ¯”è¾ƒå°æ‰€ä»¥å‡ æ¬¡è®¿é—®è¿‡åå…¨éƒ¨æ•°æ®éƒ½è¢«å­˜åˆ° CPU ç¼“å­˜ä¸­äº†ã€‚åœ¨åè€…é•¿å‘é‡çš„æƒ…å†µä¸‹ï¼Œå› ä¸ºæ•°æ®æ¯”è¾ƒå¤§ï¼Œè¿›è¡Œæ–°çš„ç´¢å¼•æ—¶ç¼“å­˜å‡ ä¹éƒ½æ²¡æœ‰å‘½ä¸­ã€‚

è¯·æ³¨æ„æ‰€èŠ±æ—¶é—´çš„å·¨å¤§å·®åˆ«â€”â€”å¤§çº¦æ˜¯70å€ã€‚
"""

# â•”â•â•¡ c6da4248-8c19-11eb-1c16-093695add9a9
md"""
å¯¹äºä¹‹å‰çš„ `random_access` å‡½æ•°ï¼Œå¦‚æœæˆ‘ä»¬ä¸æ˜¯éšæœºè®¿é—®æ•°ç»„ï¼Œè€Œæ˜¯ä»¥æœ€ç³Ÿç³•çš„æƒ…å†µè®¿é—®ï¼Œä¼šå‘ç”Ÿäº›ä»€ä¹ˆå‘¢ï¼Ÿ

ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¦‚ä¸‹çš„å‡½æ•°ï¼š
"""

# â•”â•â•¡ d4c67b82-8c1a-11eb-302f-b79c86412ce5
md"""
çº¿æ€§è¯»å–å‡½æ•° `linear_access` è¿›è¡Œä¸ `random_access` å‡ ä¹ç›¸åŒçš„æ“ä½œï¼Œä½†æ¯æ¬¡åªè®¿é—®ç¬¬ 15 ä¸ªå…ƒç´ ã€‚
Julia ä¸­ `UInt` ç±»å‹çš„é•¿åº¦ä¸º 8 å­—èŠ‚ï¼ˆ64æ¯”ç‰¹ï¼‰ï¼Œæ‰€ä»¥æ­¥é•¿ä¸º 15 è¡¨ç¤ºæ¯ä¸¤æ¬¡è®¿é—®çš„å…ƒç´ é—´çš„è·ç¦»ä¸º $15 * 8 = 120$ å­—èŠ‚ï¼Œè¿™è¶…è¿‡äº† 64 å­—èŠ‚çš„ç¼“å­˜çº¿æ‰€èƒ½å­˜å‚¨çš„å†…å®¹ã€‚ 
è¿™æ„å‘³ç€æ¯æ¬¡è®¿é—®éƒ½ä¼šè§¦å‘ç¼“å­˜æœªå‘½ä¸­â€”â€” è¿™ä¸è®¿é—®å¤§å‘é‡çš„ `random_access` å‡½æ•°ä¸åŒï¼Œå…¶ä¹Ÿåªåœ¨å¤šæ•°æƒ…å†µä¸‹å¯¼è‡´ç¼“å­˜æœªå‘½ä¸­ã€‚
"""

# â•”â•â•¡ 0f2ac53c-8c1b-11eb-3841-27f4ea1e9617
md"""
æƒŠä¸æƒŠå–œï¼Ÿæ„ä¸æ„å¤–ï¼Ÿçº¿æ€§è®¿é—®æ¨¡å¼ç«Ÿç„¶æ¯”éšæœºè®¿é—®è¦å¿« 20 å€ï¼èªæ˜çš„å°è„‘è¢‹ç“œè‚¯å®šåœ¨å¥½å¥‡è¿™æ˜¯ä¸ºä»€ä¹ˆäº†ã€‚

CPU ç¼“å­˜æ—è¾¹æœ‰ä¸€ä¸ªå«åš**é¢„å–å™¨ï¼ˆprefetcherï¼‰**çš„å°å‹ç”µè·¯ã€‚è¿™ä¸ªç”µè·¯ä¼šæ”¶é›†CPUæ‰€è®¿é—®çš„å†…å­˜ä¸Šçš„æ•°æ®ï¼Œå¹¶å¯»æ‰¾ç‰¹æ®Šæ¨¡å¼ã€‚
å½“æ£€æµ‹åˆ°è¿™äº›æ¨¡å¼æ—¶ï¼Œå®ƒä¼šæ ¹æ®è¿™ä¸ªæ¨¡å¼å»é¢„æµ‹å¹¶æå‰å–å‡ºä¸ä¹…åå¯èƒ½ä¼šè¢«è®¿é—®åˆ°çš„æ•°æ®ã€‚å› æ­¤ï¼Œå½“ CPU å‘å†…å­˜è¯·æ±‚æ•°æ®æ—¶ï¼Œæ•°æ®å…¶å®å·²ç»ä¿å­˜åœ¨ç¼“å­˜ä¸­äº†ã€‚

æˆ‘ä»¬çš„çº¿æ€§è¯»å–å‡½æ•° `linear_access` ç›¸æ¯”äºéšæœºè¯»å–å‡½æ•° `random_access`ï¼Œè™½ç„¶åœ¨**ç¼“å­˜åˆ©ç”¨ç‡** (cache usage) ä¸Šè¦æ›´å·®ï¼Œä½†å› ä¸ºå®ƒçš„è®¿é—®æ¨¡å¼æ˜¯å¯é¢„æµ‹çš„ï¼Œè¿™å°±ä½¿å¾—é¢„å­˜å™¨å‘æŒ¥äº†ä½œç”¨ã€‚

ç»¼ä¸Šï¼Œæˆ‘ä»¬å·²ç»çŸ¥é“ï¼š
* ä¸€æ¬¡**ç¼“å­˜æœªå‘½ä¸­**ä¼šå¸¦æ¥å¤§çº¦ 500 æ¬¡ CPU æ“ä½œçš„æ€§èƒ½æŸå¤±ï¼Œå› æ­¤é¿å…å®ƒä»¬æ˜¯è‡³å…³é‡è¦çš„ã€‚
* å‡å°‘ç¼“å­˜æœªå‘½ä¸­çš„æªæ–½æœ‰ï¼š
  - ä½¿ç”¨æ›´å°çš„æ•°æ®ä»è€Œæ›´å®¹æ˜“è¢«å¡è¿›ç¼“å­˜é‡Œ
  - ä»¥å¯é¢„æµ‹çš„ã€è§„å¾‹çš„æ¨¡å¼è®¿é—®æ•°æ®ï¼Œä»¥ä¾¿äºé¢„å–å™¨å‘æŒ¥ä½œç”¨ï¼›
  - è®¿é—®çš„æ•°æ®åº”è¯¥å°½å¯èƒ½åœ¨ä¸€æ®µè¿ç»­å†…å­˜ä¸­ï¼Œè€Œä¸æ˜¯åˆ†æ•£åœ¨ä¸åŒçš„åœ°æ–¹
  - å°½é‡åœ¨çŸ­æ—¶é—´å†…è®¿é—®ä¸´è¿‘çš„æ•°æ®ï¼Œå› ä¸ºè¿™æ ·çš„è¯å®ƒå¯èƒ½è¿˜åœ¨ç¼“å­˜ä¸Š

ç¼“å­˜åˆ©ç”¨ç‡ä¹Ÿä½“ç°åœ¨ä½ ä½¿ç”¨çš„æ•°æ®ç»“æ„ä¸Šã€‚å­—å…¸ `Dict` å’Œ é›†åˆ `Set è¿™ç§å“ˆå¸Œè¡¨ç»“æ„çš„ç¼“å­˜åˆ©ç”¨ç‡éƒ½å¾ˆä½ï¼Œç¼“å­˜ä¹Ÿå‡ ä¹æ€»æ˜¯æœªå‘½ä¸­ã€‚ç›¸æ¯”è€Œè¨€æ•°ç»„çš„ç¼“å­˜åˆ©ç”¨ç‡å°±æ¯”è¾ƒé«˜ã€‚
å› æ­¤ï¼Œè™½ç„¶å“ˆå¸Œè¡¨çš„è®¸å¤šæ“ä½œéƒ½æ˜¯$O(1)$ çš„å¤æ‚åº¦ï¼ˆå³åœ¨å¸¸æ•°æ—¶é—´å†…å®Œæˆï¼‰ï¼Œä½†æ˜¯æ¯æ¬¡æ“ä½œæˆæœ¬ä¾ç„¶å¾ˆé«˜ã€‚

æœ¬æ•™ç¨‹ä¸­çš„è®¸å¤šä¼˜åŒ–éƒ½ä¼šé—´æ¥å½±å“ç¼“å­˜ä½¿ç”¨ï¼Œå› æ­¤è®°ä½è¿™ä¸€ç‚¹å¾ˆé‡è¦ã€‚
"""

# â•”â•â•¡ 12f1228a-8af0-11eb-0449-230ae20bfa7a
md"""
## è®©æ•°æ®åœ¨å†…å­˜ä¸­ä¿æŒå¯¹é½
å¦‚ä¸Šé¢æ‰€è¯´ï¼ŒCPU ä¼šä¸€æ¬¡æ€§æŠŠ 512 è¿ç»­æ¯”ç‰¹ï¼ˆå³ 64 å­—èŠ‚ï¼‰çš„â€œç¼“å­˜çº¿â€æ•°æ®ä» RAM ç§»åŠ¨åˆ° CPU ç¼“å­˜ä¸­ã€‚é‚£ä¹ˆï¼Œä¸»å†…å­˜æ•´ä½“å°±ä¼šè¢«ç›¸å¯¹åˆ†æˆä¸€ä¸ªåˆä»¥ä¸€ä¸ªç¼“å­˜çº¿ã€‚
ä¾‹å¦‚ï¼Œå†…å­˜åœ°å€ 0 åˆ° 63 å¯¹åº”ä¸€æ¡ç¼“å­˜çº¿ï¼Œç´§æ¥ç€ä¸‹ä¸€æ¡æ˜¯å†…å­˜åœ°å€ 64 åˆ° 127ï¼Œå†æ¥ç€æ˜¯å†…å­˜åœ°å€ 128 åˆ° 191 ç­‰ç­‰ã€‚
CPU åªä¼šä»å†…å­˜ä¸­è¯·æ±‚æŸæ¡ç¼“å­˜çº¿ï¼Œè€Œä¸æ˜¯å†…å­˜åœ°å€ 30 åˆ° 93 æ‰€å¯¹åº”çš„ 64 å­—èŠ‚ã€‚

è¿™æ„å‘³ç€ä¸€äº›æ•°æ®ç»“æ„ä¼šç©¿è¿‡ç¼“å­˜çº¿çš„è¾¹ç•Œã€‚å¦‚æœæˆ‘æƒ³è¦è®¿é—®ä¸€ä¸ªä½äºåœ°å€ 60 çš„ 64 ä½ï¼ˆ8 å­—èŠ‚ï¼‰æ•´æ•°ï¼Œé‚£ä¹ˆ CPU å¿…é¡»é¦–å…ˆæ ¹æ®å•æ¬¡è¯·æ±‚åœ°å€ç”Ÿæˆä¸¤æ¬¡å†…å­˜è¯·æ±‚ï¼ˆå³ç¼“å­˜çº¿ 0-63 å’Œ 64-127ï¼‰ï¼Œç„¶åä»ä¸¤æ¡ç¼“å­˜çº¿ä¸­æ£€ç´¢è¯¥æ•´æ•°ï¼Œè¿™æ˜¾ç„¶ä¼šæµªè´¹æ—¶é—´ã€‚

æµªè´¹çš„æ—¶é—´å¯èƒ½ä¼šå¾ˆæ˜¾è‘—ã€‚åœ¨è¯æ˜ç¼“å­˜è®¿é—®æ˜¯ç“¶é¢ˆçš„æƒ…å†µä¸‹ï¼Œç›¸è¾ƒäºä¸å­˜åœ¨å¯¹é½é—®é¢˜çš„æƒ…å†µï¼Œç¨‹åºæ€§èƒ½ä¼šä¸‹é™ 1/2ã€‚
åœ¨æ¥ä¸‹æ¥çš„ä¾‹å­ä¸­ï¼Œæˆ‘å°†ä½¿ç”¨æŒ‡é’ˆåœ¨ç¼“å­˜çº¿è¾¹ç•Œçš„ç»™å®šåç§»å¤„é‡å¤è®¿é—®æ•°ç»„ã€‚
å¦‚æœåç§»ä½äºèŒƒå›´ `0:56`ï¼Œé‚£ä¹ˆæ‰€æœ‰çš„æ•´æ•°éƒ½å°†ä½äºä¸€æ¡ç¼“å­˜çº¿ä¸Šï¼Œå‡½æ•°è¿è¡Œèµ·æ¥ä¹Ÿå¿«ã€‚
å¦‚æœåç§»ä½äºèŒƒå›´ `57:63`ï¼Œé‚£ä¹ˆå°†ä¼šæœ‰æ•´æ•°ç©¿è¿‡ç¼“å­˜çº¿ã€‚
"""

# â•”â•â•¡ 3a1efd5a-8af0-11eb-21a2-d1011f16555c
md"æœªå¯¹é½å†…å­˜è®¿é—®çš„åæœä¾ CPU å‹å·è€Œå®šã€‚åœ¨æˆ‘ç°åœ¨çš„ CPU ä¸Šï¼Œä¼šå­˜åœ¨çº¦ 15% çš„æ€§èƒ½ä¸‹é™ã€‚
 åœ¨æˆ‘æœ€åˆå†™è¿™æœ¬æ•™ç¨‹çš„æ—§ç”µè„‘ä¸Šï¼Œæ€§èƒ½ä¸‹é™æ¥è¿‘ç™¾åˆ†ç™¾ã€‚
æ—§çš„å¤„ç†å™¨ç”šè‡³ä¼šå‡ºç°[æ›´å·®çš„æƒ…å†µ](https://www.kernel.org/doc/Documentation/unaligned-memory-access.txt) â€”â€” éš¾ä»¥ç½®ä¿¡çš„æ˜¯ï¼Œ2001 å¹´ Game Boy Advance çš„ CPU ç«Ÿç„¶ä¼š**é™é»˜æ‰§è¡Œä¸åŒçš„è¯»å–ï¼** ğŸ˜±

å¹¸è¿çš„æ˜¯ï¼Œä¸€äº›ç¼–è¯‘å™¨ç«¯çš„æŠ€å·§èƒ½å¤Ÿé™ä½è®¿é—®æœªå¯¹é½æ•°æ®çš„å¯èƒ½æ€§ã€‚é¦–å…ˆï¼ŒJuliaï¼ˆä»¥åŠå…¶ä»–ç¼–è¯‘å‹è¯­è¨€ï¼‰é€šå¸¸ä¼šæŠŠæ–°å¯¹è±¡æ”¾åœ¨ç¼“å­˜çº¿å†…å­˜çš„è¾¹ç•Œå¤„ã€‚å½“å¯¹è±¡æ­£å¥½æ”¾åœ¨è¾¹ç•Œæ—¶ï¼Œæˆ‘ä»¬è®¤ä¸ºæ•°æ®æ˜¯å¯¹é½çš„ã€‚Julia ä¹Ÿä¼šæŠŠå¤§å‹æ•°ç»„çš„å¼€å¤´å¯¹é½ï¼š"

# â•”â•â•¡ 5b10a2b6-8af0-11eb-3fe7-4b78b4c22550
md"å¦‚æœæ•°ç»„å¼€å¤´æ˜¯å¯¹é½çš„ï¼Œé‚£ä¹ˆ 1-, 2-, 4-, æˆ–è€… 8 å­—èŠ‚çš„å¯¹è±¡éƒ½ä¸å¯èƒ½ç©¿è¿‡ç¼“å­˜çº¿çš„è¾¹ç•Œã€‚å¹¶ä¸”ä¸€åˆ‡éƒ½æ˜¯å¯¹é½çš„ã€‚

ä½†æ˜¯è‹¥æ•°ç»„ä¸­æœ‰ 7 å­—èŠ‚å¯¹è±¡ï¼Œä»ç„¶å¯èƒ½å­˜åœ¨å¯¹é½ä¸äº†çš„æƒ…å†µã€‚åœ¨ä¸€ä¸ªç”± 7 å­—èŠ‚å¯¹è±¡ç»„æˆçš„æ•°ç»„ä¸­ï¼Œç¬¬ 10 ä¸ªå¯¹è±¡çš„åç§»åœ°å€æ˜¯ $7 \times (10-1) = 63$ å­—èŠ‚ï¼Œè¿™å°†ä¼šäº§ç”Ÿç©¿è¿‡ç¼“å­˜çº¿çš„æƒ…å†µã€‚ç„¶è€Œï¼Œç¼–è¯‘å™¨é€šå¸¸å› æ­¤ä¸å…è®¸éæ ‡å‡†å†…å­˜å¤§å°çš„ç»“æ„ä½“ã€‚å¦‚æœå®šä¹‰ä¸€ä¸ª 7 å­—èŠ‚ç»“æ„ä½“ï¼š"

# â•”â•â•¡ 6061dc94-8af0-11eb-215a-4f3af731774e
struct AlignmentTest
    a::UInt32 # 4 bytes +
    b::UInt16 # 2 bytes +
    c::UInt8  # 1 byte = 7 bytes?
end;

# â•”â•â•¡ 624eae74-8af0-11eb-025b-8b68dc55f31e
md"ç„¶åå¯ä»¥ä½¿ç”¨ Julia çš„å†…çœå‡½æ•°è·å¾— `AlignmentTest` ä¸­ä¸‰ä¸ªå¯¹è±¡åœ¨å†…å­˜ä¸­çš„ç›¸å¯¹ä½ç½®ï¼š"

# â•”â•â•¡ d4c8c38c-8ee6-11eb-0b49-33fbfbd214f3
let
    T = AlignmentTest
    println("Size of $T: ", sizeof(T), "bytes")
    for fieldno in 1:fieldcount(T)
        print("Name: ", fieldname(T, fieldno), '\t')
        print("Size: ", sizeof(fieldtype(T, fieldno)), '\t')
        print("Offset: ", fieldoffset(T, fieldno), '\n')
    end
end

# â•”â•â•¡ 7b979410-8af0-11eb-299c-af0a5d740c24
md"""
æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå°½ç®¡ `AlignmentTest` åªæœ‰ 4 + 2 + 1 = 7 å­—èŠ‚çš„çœŸå®æ•°æ®ï¼Œä½†æ˜¯å´åˆ†é…äº† 8 å­—èŠ‚çš„å†…å­˜ã€‚
è¿™æ ·çš„è¯ï¼Œè®¿é—®æ•°ç»„ä¸­çš„ `AlignmentTest` å¯¹è±¡æ—¶ï¼Œå†…å­˜ä»ç„¶æ˜¯å¯¹é½çš„ã€‚

ä½œä¸ºä¸€åç¨‹åºå‘˜ï¼Œå…¶å®åªæœ‰æå°‘æ•°æƒ…å†µä¼šé‡åˆ°å†…å­˜å¯¹é½é—®é¢˜ã€‚è¿™é‡Œæä¾›ä¸¤ä¸ªä¾‹å­ï¼š

1. è‹¥åˆ›å»ºçš„å¯¹è±¡å…·æœ‰å¥‡æ€ªçš„å°ºå¯¸ï¼Œä¾‹å¦‚ä½¿ç”¨æŒ‡é’ˆè®¿é—®ç¨ å¯†çš„æ•´æ•°æ•°ç»„ã€‚è¿™ç§æ“ä½œè™½ç„¶å¯ä»¥èŠ‚çº¦å†…å­˜ï¼Œä½†æ˜¯ä¼šæµªè´¹æ—¶é—´ã€‚æˆ‘å®ç°çš„[Cuckoo filter](https://github.com/jakobnissen/Probably.jl) å°±ä½¿ç”¨äº†è¿™ç§æ–¹å¼èŠ‚çº¦ç©ºé—´ã€‚ 
2. çŸ©é˜µæ“ä½œçš„è¿‡ç¨‹ã€‚å› ä¸ºæ•°ç»„å…ƒç´ åœ¨å†…å­˜ä¸­ç´§é ç€å­˜å‚¨ï¼Œæ‰€ä»¥æœ‰æ—¶æ•°ç»„çš„åˆ—ä¼šæ˜¯æœªå¯¹é½çš„ã€‚ä¾‹å¦‚ï¼Œåœ¨ä¸€ä¸ª 15x15 çš„ `Float32` çŸ©é˜µä¸­ï¼Œä»…ä»…åªæœ‰ç¬¬ä¸€åˆ—æ˜¯å¯¹é½çš„ï¼Œå…¶ä»–åˆ—éƒ½å­˜åœ¨æœªå¯¹é½é—®é¢˜ã€‚è¿™ä¼šå¯¹çŸ©é˜µæ“ä½œé€ æˆä¸¥é‡çš„åæœï¼š[åœ¨é“¾æ¥é‡Œçš„åŸºå‡†æµ‹è¯•ä¸­](https://juliasimd.github.io/LoopVectorization.jl/latest/examples/matrix_vector_ops/)ï¼Œç”±äºå¯¹é½é—®é¢˜ï¼Œ80x80 çŸ©é˜µ/å‘é‡çš„ä¹˜æ³•ä¼šæ¯” 79x79 çŸ©é˜µ/å‘é‡çš„ä¹˜æ³•å¿«ä¸Šä¸¤å€ã€‚
"""

# â•”â•â•¡ 8802ff60-8af0-11eb-21ac-b9fdbeac7c24
md"""
## é¢˜å¤–è¯ï¼šæ±‡ç¼–ä»£ç 
ä»»ä½•ç¨‹åºæƒ³è¦è¿è¡Œï¼Œéƒ½éœ€è¦å…ˆç¿»è¯‘æˆ–è€…è¯´**ç¼–è¯‘**ä¸º CPU æŒ‡ä»¤ã€‚
ä½¿ç”¨ç¼–ç¨‹è¯­è¨€å†™ä¸‹çš„ä»£ç ä»…ä»…æ˜¯ç¨‹åºçš„ä¸€ç§**æè¿°**ï¼Œä¸ä¹‹ç›¸åçš„æ˜¯ï¼ŒCPU æŒ‡ä»¤æ˜¯çœŸçœŸåˆ‡åˆ‡è¿è¡Œåœ¨ç”µè„‘ä¸Šçš„ã€‚
äººä»¬é€šå¸¸ç”¨ **æ±‡ç¼–** è¯­è¨€æè¿° CPU æŒ‡ä»¤ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ±‡ç¼–è¯­è¨€çš„è¯­å¥æ˜¯ä¸ CPU æŒ‡ä»¤ä¸€ä¸€å¯¹åº”çš„ã€‚

æŸ¥çœ‹æ±‡ç¼–ä»£ç å°†æœ‰åŠ©äºç†è§£ä¸‹æ–‡ä¸­é‚£äº›å…³äº CPU æŒ‡ä»¤çš„ç« èŠ‚ã€‚

åœ¨ Julia ä¸­ï¼Œå¯ä»¥ä½¿ç”¨  `code_native` å‡½æ•°æˆ–è€… `@code_native` å®æ–¹ä¾¿åœ°æŸ¥çœ‹ç¼–è¯‘åçš„æ±‡ç¼–ä»£ç ã€‚
æˆ‘ä»¬å°†å°†å…¶åº”ç”¨åˆ°ä¸€ä¸ªç®€å•çš„å‡½æ•°ä¸Šï¼š
"""

# â•”â•â•¡ a36582d4-8af0-11eb-2b5a-e577c5ed07e2
# View assembly code generated from this function call
function foo(x)
    s = zero(eltype(x))
    @inbounds for i in eachindex(x)
        s = x[i âŠ» s]
    end
    return s
end;

# â•”â•â•¡ a74a9966-8af0-11eb-350f-6787d2759eba
 @code_native foo([UInt(1)])

# â•”â•â•¡ ae9ee028-8af0-11eb-10c0-6f2db3ab8025
md"""
è®©æˆ‘ä»¬æ¥åˆ†æä¸€ä¸‹ï¼š

ä»¥ `;` å¼€å¤´çš„è¡Œæ˜¯æ³¨é‡Šï¼Œè¿™äº›è¡Œä¼šè§£é‡Šè¯´æ˜ä»¥ä¸‹ä»£ç æ¥è‡ªå“ªäº›éƒ¨åˆ†ã€‚
å®ƒä»¬ä¼šå±•ç¤ºåµŒå¥—çš„å‡½æ•°è°ƒç”¨ï¼Œä»¥åŠå‡½æ•°åœ¨æºä»£ç ä¸­çš„ä½ç½®ã€‚
ä½ å¯ä»¥çœ‹åˆ°ï¼Œ`eachindex` è°ƒç”¨äº† `axes1`ï¼Œ`axes1` åˆè°ƒç”¨äº† `axes`ï¼Œç„¶å `axes` åˆè°ƒç”¨äº† `size`ã€‚
åœ¨ `size` é‚£è¡Œæ³¨é‡Šä¸‹é¢ï¼Œæˆ‘ä»¬çœ‹åˆ°äº†ç¬¬ä¸€æ¡ CPU æŒ‡ä»¤ã€‚
æŒ‡ä»¤åä½äºæœ€å·¦ä¾§ï¼Œå³ `movq`ã€‚
åç§°ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œç¬¬ä¸€éƒ¨åˆ†ä¸º `mov`ï¼Œå®ƒæ˜¯æŒ‡ä»¤çš„ç±»å‹ï¼ˆå³å°†æ•°æ®ç§»å‡ºæˆ–ç§»å…¥å¯„å­˜å™¨ï¼‰ï¼›ç¬¬äºŒéƒ¨åˆ†æ˜¯åç¼€ `q`ï¼Œè¿™æ˜¯ "quad" çš„ç¼©å†™ï¼Œå¯¹åº”äº† 64-bit æ•´æ•°ã€‚
å…¨éƒ¨çš„åç¼€å¦‚ä¸‹ï¼š`b` (byte, 8 ä½), `w` (word, 16 ä½), `l`, (long, 32 ä½) å’Œ `q` (quad, 64 ä½)ã€‚

æŒ‡ä»¤ä¸­æ¥ç€çš„ä¸¤åˆ—ï¼Œ`24(%rdi)` å’Œ `%rax` æ˜¯ `movq` çš„å‚æ•°ã€‚
å®ƒä»¬éƒ½æ˜¯å­˜å‚¨å¾…æ“ä½œæ•°æ®çš„å¯„å­˜å™¨çš„åå­—ã€‚åæ–‡å°†ä¼šè¯¦ç»†è®¨è®ºå¯„å­˜å™¨ã€‚

æŸ¥çœ‹å¤§ç¨‹åºçš„æ±‡ç¼–ä»£ç å¯ä»¥å‘ç°ï¼Œæ±‡ç¼–ä»£ç è¢«åˆ†æˆäº†ä¸åŒçš„èŠ‚ï¼Œå¹¶ä¸”è¿™äº›èŠ‚çš„å‘½åéƒ½ä»¥â€œLâ€å¼€å¤´ã€‚
ä¾‹å¦‚ï¼Œå½“è¿è¡Œä¸Šé¢çš„å‡½æ•°æ—¶ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ° `L32` èŠ‚ã€‚è¿™äº›èŠ‚åœ¨ if è¯­å¥æˆ–è€…**ä»£ç åˆ†æ”¯**é—´è·³è½¬ã€‚è¿™é‡Œçš„ `L32` èŠ‚å¯¹åº”äº†å¾ªç¯æ“ä½œã€‚ä½ å¯ä»¥åœ¨ `L32` èŠ‚çœ‹åˆ°å¦‚ä¸‹ä¸¤æ¡æŒ‡ä»¤ï¼š

```
; â”‚â”‚â”Œ @ promotion.jl:401 within `=='
     cmpq    $1, %rdi
; â”‚â””â””
     jne     L32
```

ç¬¬ä¸€æ¡æŒ‡ä»¤ `cmpq`ï¼ˆcompare quadï¼‰ ä¼šå°†å¯„å­˜å™¨ `rdi` ä¸­çš„æ•°æ®ä¸æ•°å­— 1 è¿›è¡Œæ¯”è¾ƒï¼Œç„¶åæ ¹æ®ç»“æœåœ¨ CPU ä¸­è®¾å®šä¸€äº› flagã€‚
å…¶ä¸­ï¼Œå¯„å­˜å™¨ `rdi` ä¸­çš„æ•°æ®å¯¹åº”äº†å‰©ä½™çš„è¿­ä»£æ¬¡æ•°ï¼ˆåŠ  1ï¼‰ã€‚
ä¸‹ä¸€æ¡æŒ‡ä»¤ `jne`ï¼ˆjump if not equalï¼Œ å¦‚æœä¸ç­‰åˆ™è·³è½¬ï¼‰ä¼šåœ¨ CPU æœªè®¾ç½® "equal" flag æ—¶å‘ç”Ÿè·³è½¬ã€‚å³å½“è¿˜æœ‰ä¸€æ¬¡æˆ–å¤šæ¬¡è¿­ä»£æœªæ‰§è¡Œæ—¶ï¼Œç¨‹åºå‘ç”Ÿè·³è½¬ã€‚è¿™æ¡æŒ‡ä»¤ä¼šè·³è½¬åˆ° 'L32' èŠ‚ï¼Œè¿™æ„å‘³ç€ä¼šé‡å¤æ‰§è¡Œè¯¥éƒ¨åˆ†ã€‚
"""

# â•”â•â•¡ b73b5eaa-8af0-11eb-191f-cd15de19bc38
md"""
#### å¿«æŒ‡ä»¤ä¸æ…¢æŒ‡ä»¤
å¹¶ä¸æ˜¯æ‰€æœ‰çš„ CPU æŒ‡ä»¤éƒ½å¾ˆå¿«ã€‚ä¸‹è¡¨å±•ç¤ºäº†ä¸€äº› CPU æŒ‡ä»¤ï¼Œå¹¶ç²—ç•¥ä¼°è®¡äº†è¿è¡Œå®ƒä»¬æ‰€è¦æ¶ˆè€—çš„æ—¶é’Ÿå‘¨æœŸæ•°ã€‚
äº†è§£æ›´å¤šç»†èŠ‚è¯·æŸ¥çœ‹[æ­¤æ–‡æ¡£](https://www.agner.org/optimize/instruction_tables.pdf) ã€‚
ä¸‹æ–‡å°†æ€»ç»“ç°ä»£ Intel CPU çš„æŒ‡ä»¤é€Ÿåº¦ã€‚ç°ä»£ CPU çš„æŒ‡ä»¤é€Ÿåº¦éƒ½å·®ä¸å¤šã€‚

å¯ä»¥çœ‹åˆ°ï¼Œè¡¨ä¸­æ—¶é—´çš„è¡¡é‡æ ‡å‡†æ˜¯å»¶è¿Ÿå’Œååé‡å€’æ•°ï¼ˆå³ï¼Œ$1/ååé‡$ï¼‰ã€‚
è¿™æ ·åšçš„åŸå› æ˜¯ CPU åŒ…å«æœ‰å¤šä¸ªç”µè·¯ï¼Œå¹¶ä¸”è¿™äº›ç”µè·¯å¯ä»¥å¹¶è¡Œåœ°è¿è¡Œæ“ä½œã€‚
å› æ­¤ï¼Œå°½ç®¡æµ®ç‚¹æ•°ä¹˜æ³•æœ‰ 5 ä¸ªæ—¶é’Ÿå‘¨æœŸçš„å»¶è¿Ÿï¼Œä½†æ˜¯10ä¸ªæµ®ç‚¹æ•°æ“ä½œå¯ä»¥åœ¨10ä¸ªä¸åŒçš„ç”µè·¯å¹¶è¡Œåœ°è®¡ç®—ã€‚
æ­¤æ—¶ååé‡ä¸º 2 æ“ä½œ/ç§’ï¼Œæ‰€ä»¥ååé‡å€’æ•°ä¸º 0.5ã€‚

ä¸‹è¡¨ä»¥æ—¶é’Ÿå‘¨æœŸä¸ºæ—¶é—´å•ä½ï¼š

|Instruction             |Latency|Rec. throughp.|
|------------------------|-------|--------------|
|move data               |  1 |  0.25
|and/or/xor              |  1 |  0.25
|test/compare            |  1 |  0.25
|do nothing              |  1 |  0.25
|int add/subtract        |  1 |  0.25
|bitshift                |  1 |  0.5
|float multiplication    |  5 |  0.5
|vector int and/or/xor   |  1 |  0.5
|vector int add/sub      |  1 |  0.5
|vector float add/sub    |  4 |  0.5
|vector float multiplic. |  5 |  0.5
|lea                     |  3 |  1
|int multiplic           |  3 |  1
|float add/sub           |  3 |  1
|float multiplic.        |  5 |  1
|float division          | 15 |  5
|vector float division   | 13 |  8
|integer division        | 50 | 40


`lea`æŒ‡ä»¤æ¥æ”¶ 3 ä¸ªå‚æ•°ï¼ŒAï¼ŒB å’Œ Cã€‚å…¶ä¸­ A å¿…é¡»ä¸º1, 2ï¼Œ4 æˆ– 8ï¼Œç„¶åè®¡ç®— AB + Cã€‚
ç¨åä¼šè®¨è®º "vector" æŒ‡ä»¤å¹²äº†ä»€ä¹ˆã€‚

ä¸ºäº†è¿›è¡Œæ¯”è¾ƒï¼Œä¸€äº›å…¶ä»–å»¶è¿Ÿæ¥æºçš„**ç²—ç•¥ä¼°è®¡**è¡¥å……å¦‚ä¸‹ï¼š

|Delay                  |Cycles|
|-----------------------|----|
|move memory from cache |        1
|misaligned memory read |       10
|cache miss             |      500
|read from disk         | 5000000
"""

# â•”â•â•¡ c0c757b2-8af0-11eb-38f1-3bc3ec4c43bc
md"å¦‚æœä½ çš„å†…å±‚å¾ªç¯éœ€è¦æ‰§è¡Œä¸Šç™¾ä¸‡æ¬¡ï¼Œé‚£ä¹ˆå°±è¦æ£€æŸ¥ç”Ÿæˆçš„æ±‡ç¼–ä»£ç æ˜¯å¦å¯ä»¥è½¬åŒ–ä¸º CPU å¿«æŒ‡ä»¤è¡¨ç¤ºï¼Œè¿™é¡¹æ“ä½œå¾ˆå¯èƒ½æ˜¯æœ‰æ”¶ç›Šçš„ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä½ æœ‰ä¸€ä¸ªå¤§äºç­‰äº 0 çš„æ•´æ•°ï¼Œæ‰“ç®—ç”¨ 8 é™¤ä»¥å®ƒï¼ˆå¿½ç•¥ä½™æ•°ï¼‰ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ä½åç§»æ“ä½œï¼Œå› ä¸ºä½åç§»æ“ä½œè¦æ¯”æ•´æ•°é™¤æ³•å¿«ï¼š"

# â•”â•â•¡ c5472fb0-8af0-11eb-04f1-95a1f7b6b9e0
begin
    divide_slow(x) = div(x, 8)
    divide_fast(x) = x >>> 3;
end;

# â•”â•â•¡ ce0e65d4-8af0-11eb-0c86-2105c26b62eb
md"ç„¶è€Œï¼Œç°ä»£ç¼–è¯‘å™¨éå¸¸æ™ºèƒ½ï¼Œå¸¸å¸¸èƒ½å¤Ÿåœ¨ä¿è¯ç»“æœç›¸åŒçš„æƒ…å†µä¸‹æ‰¾å‡ºå‡½æ•°æ‰€å¯¹åº”çš„æœ€ä½³æŒ‡ä»¤ã€‚ä¾‹å¦‚ï¼Œæ•´é™¤æŒ‡ä»¤ `idivq`ä¼šè¢«æ›¿æ¢ä¸ºå³ä½ç§»æŒ‡ä»¤ï¼ˆ`shrq`ï¼‰ï¼Œåè€…åœ¨åˆé€‚çš„æ—¶å€™è¿ç®—æ›´å¿«ã€‚ä½ éœ€è¦è‡ªè¡ŒæŸ¥çœ‹æ±‡ç¼–ä»£ç ï¼š"

# â•”â•â•¡ d376016a-8af0-11eb-3a15-4322759143d1
# Calling it with debuginfo=:none removes the comments in the assembly code
@code_native debuginfo=:none dump_module=false divide_slow(UInt(1))

# â•”â•â•¡ d70c56bc-8af0-11eb-1220-09e78dba26f7
md"## å†…å­˜åˆ†é…å’Œä¸å¯å˜æ€§
å¦‚å‰æ–‡æ‰€è¿°ï¼Œä¸» RAM è¦æ¯” CPU ç¼“å­˜æ…¢ã€‚ç„¶è€Œï¼Œåœ¨ä¸» RAM ä¸­å·¥ä½œè¿˜æœ‰å¦å¤–çš„ç¼ºç‚¹ï¼šæ“ä½œç³»ç»Ÿï¼ˆoperating systemï¼ŒOSï¼‰ä¼šç»™å¤šä¸ªåº”ç”¨æä¾›ä¸åŒçš„RAMã€‚åœ¨å†…å­˜å—ä¸­ï¼Œç¨‹åºè‡ªå·±éœ€è¦è¿½è¸ªå¯¹è±¡æ­£åœ¨ä½¿ç”¨å“ªäº›RAMã€‚è‹¥ä¸è¿½è¸ªï¼Œ ä¸€ä¸ªå¯¹è±¡çš„åˆ†é…å†…å­˜å°±å¯èƒ½è¦†ç›–å¦ä¸€ä¸ªï¼Œè¿™åˆ™ä¼šæ•°æ®ä¸¢å¤±ã€‚å› æ­¤ï¼ŒRAMéœ€è¦èŠ±æ—¶é—´è®°å½•æ¯ä»½æ•°æ®çš„äº§ç”Ÿå’Œé”€æ¯ã€‚

RAM ä¸­åˆ›å»ºæ–°å¯¹è±¡ç§°ä¸º **åˆ†é…ï¼ˆallocationï¼‰**ï¼Œå¯¹åº”åœ°ï¼Œé”€æ¯å¯¹è±¡ç§°ä¸º **é‡Šæ”¾ï¼ˆdeallocationï¼‰**ã€‚å®é™…ä¸Šï¼Œåˆ†é…ï¼ˆé‡Šæ”¾ï¼‰æœ¬è´¨ä¸Šå¹¶ä¸æ˜¯çœŸçš„åœ¨ **åˆ›é€ ** æˆ– **é”€æ¯** ï¼Œè€Œæ˜¯å¼€å§‹æˆ–åœæ­¢è¿½è¸ªæŒ‡å®šçš„å†…å­˜ã€‚æœªè¢«è¿½è¸ªçš„å†…å­˜å°†ä¼šè¢«å…¶ä»–æ•°æ®è¦†ç›–ã€‚åˆ†é…å’Œé‡Šæ”¾æ‰€èŠ±è´¹çš„æ—¶é—´å–å†³äºå¯¹è±¡çš„å¤§å°ï¼Œæ¯æ¬¡æ“ä½œçš„æ•°é‡çº§åœ¨æ•°å ns åˆ°å‡  ms ä¹‹é—´ã€‚

Juliaã€Pythonã€R å’Œ Java ç­‰è¯­è¨€ä½¿ç”¨åä¸ºâ€œåƒåœ¾å›æ”¶å™¨ï¼ˆgarbage collectorï¼ŒGCï¼‰â€çš„ç¨‹åºè‡ªåŠ¨å®ç°é‡Šæ”¾æ“ä½œã€‚æ­¤ç¨‹åºä¼šè¿½è¸ªé‚£äº›è¢«ç¨‹åºå‘˜æ ‡è®°ä¸ºä¸å¯è®¿é—®çš„å¯¹è±¡ï¼Œç„¶åé‡Šæ”¾å®ƒä»¬ã€‚ä¾‹å¦‚è‹¥è¿™æ ·å†™ï¼š"

# â•”â•â•¡ dc24f5a0-8af0-11eb-0332-2bc0834d426c
begin
    thing = [1,2,3]
    thing = nothing
end

# â•”â•â•¡ e3c136de-8af0-11eb-06f1-9393c0f95fbb
md"é‚£ä¹ˆä½ å°†æ— æ³•æ‰¾å›åŸæ¥çš„æ•°ç»„ `[1,2,3]` ï¼Œå®ƒå·²ç»æ— æ³•è®¿é—®ã€‚è¿™ä»€ä¹ˆä¹Ÿæ²¡æœ‰åšï¼Œåªæ˜¯åœ¨æµªè´¹ RAMã€‚å®ƒæ˜¯**åƒåœ¾**ã€‚åˆ†é…å’Œé‡Šæ”¾æœ‰æ—¶ä¼šå¯¼è‡´ GC å¼€å§‹æ‰«ææ‰€æœ‰å†…å­˜ä¸­çš„å¯¹è±¡å¹¶é‡Šæ”¾æ— æ³•è®¿é—®çš„å¯¹è±¡ï¼Œè€Œè¿™æ ·ä¼šå¸¦æ¥æ˜¾è‘—çš„å»¶è¿Ÿã€‚å› æ­¤ä½ ä¹Ÿå¯ä»¥æ‰‹åŠ¨å¼€å§‹åƒåœ¾å›æ”¶ï¼š"

# â•”â•â•¡ e836dac8-8af0-11eb-1865-e3feeb011fc4
GC.gc()

# â•”â•â•¡ ecfd04e4-8af0-11eb-0962-f548d2eabad3
md"ä¸‹é¢çš„ä¾‹å­å±•ç¤ºäº†ä¸ºç»“æœåˆ†é…æ–°å†…å­˜çš„ç¨‹åºå’Œç›´æ¥åœ¨åŸå‘é‡ä¸Šæ›´æ”¹çš„ç¨‹åºä¹‹é—´çš„ç”¨æ—¶å·®å¼‚ï¼š"

# â•”â•â•¡ f0e24b50-8af0-11eb-1a0e-5d925f3743e0
begin
    function increment(x::Vector{<:Integer})
        y = similar(x)
        @inbounds for i in eachindex(x)
            y[i] = x[i] + 1
        end
        return y
    end

    function increment!(x::Vector{<:Integer})
        @inbounds for i in eachindex(x)
            x[i] = x[i] + 1
        end
        return x
    end
end;

# â•”â•â•¡ 22512ab2-8af1-11eb-260b-8d6c16762547
md"""
åœ¨æˆ‘çš„ç”µè„‘ä¸Šï¼Œéœ€è¦åˆ†é…æ–°å†…å­˜çš„ç¨‹åºå¹³å‡ç›¸æ¯”ä¹‹ä¸‹è¦æ…¢15å€ã€‚å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿéœ€è¦å…³æ³¨å‡½æ•°å†…å­˜åˆ†é…æ‰€èŠ±è´¹æ—¶é—´çš„æœ€å¤§å€¼ã€‚è¿™æ˜¯å› ä¸ºä»£ç å…·æœ‰ä»¥ä¸‹æ€§è´¨ï¼š
* é¦–å…ˆï¼Œåˆ†é…åŠ¨ä½œæœ¬èº«éœ€è¦èŠ±è´¹æ—¶é—´ï¼›
* å…¶æ¬¡ï¼Œå·²åˆ†é…å¯¹è±¡çš„é”€æ¯ä¹Ÿéœ€è¦èŠ±è´¹æ—¶é—´ï¼›
* ç¬¬ä¸‰ï¼Œé‡å¤çš„åˆ†é…ä¼šè§¦å‘åƒåœ¾å›æ”¶ï¼Œè¿™åˆä¼šå¸¦æ¥é¢å¤–çš„å¼€é”€
* ç¬¬å››ï¼Œè¶Šå¤šçš„åˆ†é…æœ‰æ—¶æ„å‘³ç€è¶Šä½æ•ˆçš„ç¼“å­˜åˆ©ç”¨ï¼Œå› ä¸ºä½¿ç”¨äº†æ›´å¤šçš„å†…å­˜ 

æ³¨æ„åˆ°ï¼Œæˆ‘ä½¿ç”¨çš„æ˜¯æ—¶é—´çš„å¹³å‡å€¼ï¼Œè€Œä¸æ˜¯ä¸­ä½æ•°ï¼Œè¿™æ˜¯å› ä¸ºå¤§çº¦æ¯ 30 æ¬¡å‡½æ•°è°ƒç”¨æ‰ä¼šè§¦å‘ 1 æ¬¡GCï¼Œæ¯æ¬¡GCèŠ±è´¹ 30-40 Âµsã€‚ç»¼ä¸Šï¼Œé«˜æ€§èƒ½ä»£ç åº”å°†å†…å­˜åˆ†é…ä¿æŒåœ¨æœ€ä½é™åº¦ã€‚

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `@btime` å®æˆ–è€…å…¶ä»–åŸºå‡†æµ‹è¯•å·¥å…·è·å–åˆ°å†…å­˜åˆ†é…çš„æ¬¡æ•°ã€‚æä¾›æ­¤ä¿¡æ¯çš„åŸå› æ˜¯é€šå¸¸è®¤ä¸ºç»™ä»£ç åšåŸºå‡†æµ‹è¯•çš„å¼€å‘è€…éƒ½ä¼šå¯¹å‡å°‘å†…å­˜åˆ†é…æ„Ÿå…´è¶£ã€‚

#### å¹¶ééœ€è¦åˆ†é…æ‰€æœ‰å¯¹è±¡
åœ¨ RAM ä¸­ï¼Œæ•°æ®é€šå¸¸ä¿å­˜åœ¨ **æ ˆ** æˆ– **å †** ä¸Šã€‚æ ˆæ˜¯å…·æœ‰èµ·å¤´å’Œç»“å°¾çš„ç®€å•æ•°æ®ç»“æ„ï¼Œç±»ä¼¼äº Julia ä¸­çš„ `Vector`ã€‚æ ˆçš„ä¿®æ”¹æ–¹å¼åªèƒ½æ˜¯åœ¨ç»“å°¾æ·»åŠ æˆ–ç§»é™¤å…ƒç´ ï¼Œå¯ç±»æ¯”äºåªæ”¯æŒå¯å˜æ“ä½œ `push!` å’Œ `pop!` çš„ `Vector`ã€‚è¿™äº›åœ¨æ ˆä¸Šçš„æ“ä½œéå¸¸å¿«ã€‚ç„¶è€Œï¼Œå½“æˆ‘ä»¬è®¨è®ºâ€œåˆ†é…â€æ—¶ï¼Œæˆ‘ä»¬è®¨è®ºçš„æ˜¯å †ä¸Šçš„æ•°æ®ã€‚ä¸æ ˆä¸åŒçš„æ˜¯ï¼Œå †å…·æœ‰æ— é™åˆ¶çš„å¤§å°ï¼ˆå®é™…ä¸Šé™æ˜¯è®¡ç®—æœº RAM çš„å¤§å°ï¼‰ï¼Œå¹¶ä¸”å¯ä»¥éšæ„æ›´æ”¹ã€åˆ é™¤å’Œè®¿é—®ä»»ä½•å¯¹è±¡ã€‚ä½ å¯ä»¥è®¤ä¸ºæ ˆåƒ `Vector`ï¼Œè€Œå †åƒ `Dict`ã€‚

ç›´è§‚åœ°è®²ï¼Œå¾ˆæ˜æ˜¾æˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰çš„å¯¹è±¡æ”¾åœ¨ RAM ä¸­ï¼Œå¹¶ä¸”è¦è®©ç¨‹åºéšæ—¶èƒ½å¤Ÿæ£€ç´¢å’Œåˆ é™¤å¯¹è±¡ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å°†å¯¹è±¡éƒ½åˆ†é…åœ¨å †ä¸Šã€‚æŸäº›è¯­è¨€ï¼Œæ¯”å¦‚ Pythonï¼Œæ­£æ˜¯è¿™æ ·åšçš„ã€‚ç„¶è€Œï¼Œè¿™ä¸é€‚ç”¨äº Julia ä»¥åŠå…¶ä»–é«˜æ•ˆçš„ç¼–è¯‘å‹è¯­è¨€ã€‚ä¾‹å¦‚ï¼Œæ•´æ•°ç±»å‹ï¼ˆIntegerï¼‰é€šå¸¸æ”¾åœ¨æ ˆä¸Šã€‚

ä¸ºä»€ä¹ˆæœ‰çš„å¯¹è±¡éœ€è¦åˆ†é…åœ¨å †ä¸Šï¼Œè€Œæœ‰çš„å¯¹è±¡åˆéœ€è¦åˆ†é…åœ¨æ ˆä¸Šå‘¢ï¼Ÿå¯¹äºåˆ†é…åœ¨æ ˆä¸Šçš„å¯¹è±¡ï¼Œç¼–è¯‘å™¨éœ€è¦ç¡®å®šçš„æ˜¯ï¼š

* å¯¹è±¡æ‰€å å†…å­˜åº”é€‚å½“åœ°å°ï¼Œå› æ­¤æ‰èƒ½æ”¾è¿›æ ˆä¸­ã€‚è€ƒè™‘ä¸€äº›æŠ€æœ¯å› ç´ ï¼Œæ ˆä¸èƒ½åªæœ‰æ•°ç™¾ MB å¤§å°ã€‚  
* ç¼–è¯‘å™¨åº”è¯¥èƒ½å¤Ÿå‡†ç¡®é¢„æµ‹å¯¹è±¡çš„åˆ›å»ºå’Œé”€æ¯æ—¶æœºï¼Œå› æ­¤å¯ä»¥é€šè¿‡ç®€å•çš„å¼¹æ ˆæ“ä½œæ¥åŠæ—¶é”€æ¯å¯¹è±¡ï¼ˆç±»ä¼¼äºè°ƒç”¨ `pop!` å‡½æ•°æ“ä½œ `Vector`ï¼‰ã€‚ç¼–è¯‘å‹è¯­è¨€ä¸­çš„å±€éƒ¨å˜é‡é€šå¸¸å°±æ˜¯è¿™ç±»æƒ…å½¢ã€‚

Julia è¯­è¨€å¯¹åˆ†é…åœ¨æ ˆä¸Šçš„å¯¹è±¡æœ‰æ›´å¤šçš„é™åˆ¶ã€‚
* å¯¹è±¡çš„å¤§å°å›ºå®šï¼Œä¸”èƒ½å¤Ÿåœ¨ç¼–è¯‘æ—¶å·²çŸ¥ã€‚
* ç¼–è¯‘å™¨å¿…é¡»ç¡®å®šå¯¹è±¡æ°¸ä¸æ”¹å˜ã€‚CPU èƒ½å¤Ÿè‡ªç”±å¤åˆ¶æ ˆä¸Šåˆ†é…çš„å¯¹è±¡ï¼Œç„¶è€Œå¯¹äºä¸å¯å˜å¯¹è±¡ï¼Œæˆ‘ä»¬æ— æ³•åŒºåˆ†åŸå§‹å¯¹è±¡å’Œå…¶å‰¯æœ¬ã€‚è¿™éœ€è¦é‡å¤ä¸€éï¼š**å¯¹äºä¸å¯å˜å¯¹è±¡ï¼Œæˆ‘ä»¬æ— æ³•åŒºåˆ†åŸå§‹å¯¹è±¡å’Œå…¶å‰¯æœ¬**ã€‚è¿™ä½¿å¾—ç¼–è¯‘å™¨å’Œ CPU åœ¨æ“ä½œå¯¹è±¡æ—¶å…·æœ‰ç¡®å®šçš„è‡ªç”±åº¦ã€‚è¿™ä¹Ÿå°±æ˜¯ä¸ºä»€ä¹ˆ Julia ä¸­çš„å¯¹è±¡é»˜è®¤éƒ½æ˜¯ä¸å¯å˜çš„ï¼Œè¿™å¼•å‡ºäº†ä¸€æ¡æ€§èƒ½å»ºè®®ï¼šå°½å¯èƒ½ä½¿ç”¨ä¸å¯å˜å¯¹è±¡ã€‚

å®é™…ä¸Šè¿™æ„å‘³ç€ä»€ä¹ˆå‘¢ï¼Ÿåœ¨ Julia ä¸­ï¼Œè¿™æ„å‘³ç€å¦‚æœæƒ³è¦å¾—åˆ°å¿«é€Ÿçš„æ ˆåˆ†é…å¯¹è±¡ï¼Œé‚£ä¹ˆéœ€è¦æ»¡è¶³ä»¥ä¸‹æ¡ä»¶ï¼š
* å¯¹è±¡åº”è¯¥ç”±å®Œå…¨ç¼–è¯‘çš„å‡½æ•°åˆ›å»ºã€ä½¿ç”¨å’Œé”€æ¯ï¼Œä»è€Œè®©ç¼–è¯‘å™¨èƒ½å¤ŸçŸ¥é“åˆ›å»ºã€ä½¿ç”¨å’Œé”€æ¯è¯¥å¯¹è±¡çš„å‡†ç¡®æ—¶æœºã€‚å¦‚æœå¯¹è±¡éœ€è¦è¿”å›ä¾›ä»¥åä½¿ç”¨ï¼ˆè€Œä¸æ˜¯å³åˆ»è¿”å›åˆ°å¦ä¸€ä¸ªå®Œå…¨ç¼–è¯‘çš„å‡½æ•°ï¼‰ï¼Œè¿™ç§°ä¸º**é€ƒé€¸**ï¼Œåˆ™éœ€è¦åœ¨å†…å­˜ä¸­åˆ†é…ã€‚
* å¿…é¡»é™åˆ¶ç±»å‹çš„å¤§å°ã€‚æˆ‘ä¸çŸ¥é“åˆ°åº•åº”è¯¥å¤šå¤§ï¼Œä½† 100 æ¯”ç‰¹æ˜¯å¯ä»¥çš„ã€‚
* ç¼–è¯‘å™¨å¿…é¡»ï¼ˆå‡ ä¹æ€»æ˜¯ï¼‰çŸ¥é“ç±»å‹çš„å‡†ç¡®å†…å­˜å¸ƒå±€ã€‚
"""

# â•”â•â•¡ 2a7c1fc6-8af1-11eb-2909-554597aa2949
begin
    abstract type AllocatedInteger end

    struct StackAllocated <: AllocatedInteger
        x::Int
    end

    mutable struct HeapAllocated <: AllocatedInteger
        x::Int
    end
end

# â•”â•â•¡ 2e3304fe-8af1-11eb-0f6a-0f84d58326bf
md"æˆ‘ä»¬å¯ä»¥åˆ†åˆ«æ£€æŸ¥åˆå§‹åŒ– `HeapAllocated` å¯¹è±¡å’Œ `StackAllocated` å¯¹è±¡çš„ä»£ç ï¼š"

# â•”â•â•¡ 33350038-8af1-11eb-1ff5-6d42d86491a3
@code_native debuginfo=:none dump_module=false HeapAllocated(1)

# â•”â•â•¡ 3713a8da-8af1-11eb-2cb2-1957455227d0
md"æ³¨æ„ä¸Šè¿° `HeapAllocated` ä»£ç ä¸­çš„ `callq` æŒ‡ä»¤ã€‚è¿™æ¡æŒ‡ä»¤è°ƒç”¨äº†å¦ä¸€å‡½æ•°ï¼Œè¿™å®é™…ä¸Šæ„å‘³ç€éœ€è¦æ›´å¤šçš„ä»£ç æ¥åˆ›å»ºå¦‚ä¸Šæ‰€ç¤ºçš„ `HeapAllocated` å¯¹è±¡ã€‚ç›¸åï¼Œ`StackAllocated` å¯¹è±¡çš„åˆ†é…åªéœ€è¦å‡ æ¡æŒ‡ä»¤ï¼š"

# â•”â•â•¡ 59f58f1c-8af1-11eb-2e88-997e9d4bcc48
@code_native debuginfo=:none dump_module=false StackAllocated(1)

# â•”â•â•¡ 5c86e276-8af1-11eb-2b2e-3386e6795f37
md"
å› ä¸ºä¸å¯å˜å¯¹è±¡ä¸éœ€è¦å­˜å‚¨åœ¨å †ä¸Šï¼Œå¹¶ä¸”å¯ä»¥è¢«è‡ªç”±å¤åˆ¶ï¼Œæ‰€ä»¥ä¸å¯å˜å¯¹è±¡ä¸²è”å­˜å‚¨åœ¨æ•°ç»„ä¸­ã€‚è¿™æ„å‘³ç€ä¸å¯å˜å¯¹è±¡å¯ä»¥ç›´æ¥å­˜å‚¨åœ¨æ•°ç»„çš„å†…å­˜ä¸­ã€‚å¯å˜å¯¹è±¡åˆ™éœ€è¦åœ¨å †ä¸Šå…·æœ‰å”¯ä¸€çš„æ ‡è¯†ç¬¦å’Œå­˜å‚¨ä½ç½®ã€‚å¯å˜å¯¹è±¡å’Œå…¶å‰¯æœ¬é—´æ˜¯å¯åˆ†è¾¨çš„ï¼Œå› æ­¤ä¸èƒ½è‡ªç”±å¤åˆ¶ï¼Œæ‰€ä»¥æ•°ç»„å†…åŒ…å«çš„æ˜¯å¯¹å…¶å †ä¸Šå­˜å‚¨ä½ç½®çš„å¼•ç”¨ã€‚ä»æ•°ç»„è®¿é—®è¿™ç±»å¯¹è±¡çš„æµç¨‹æ˜¯ï¼Œé¦–å…ˆè®¿é—®æ•°ç»„è·å¾—å­˜å‚¨ä½ç½®ï¼Œç„¶ååˆ©ç”¨å­˜å‚¨ä½ç½®è®¿é—®å¯¹è±¡æœ¬èº«ã€‚é™¤äº†ä¸¤æ¬¡å†…å­˜è®¿é—®å¤–ï¼Œåœ¨å †ä¸Šå­˜å‚¨å¯¹è±¡ä¹Ÿç›¸å¯¹ä½æ•ˆï¼Œå› ä¸ºéœ€è¦ CPU ç¼“å­˜æ‹·è´äº†æ›´å¤šçš„å†…å­˜ï¼Œè€Œè¿™æ„å‘³ç€æ›´å¤šçš„ç¼“å­˜æœªå‘½ä¸­ã€‚å› æ­¤ï¼Œå³ä½¿æ˜¯å­˜å‚¨åœ¨å †ä¸Šçš„æ•°ç»„é‡Œï¼Œä¸å¯å˜å¯¹è±¡çš„å­˜å‚¨ä¹Ÿç›¸å¯¹æ›´é«˜æ•ˆã€‚
"

# â•”â•â•¡ 6849d9ec-8af1-11eb-06d6-db49af4796bc
md"æˆ‘ä»¬å¯ä»¥éªŒè¯ï¼Œå®é™…ä¸Šï¼Œ`data_stack` ä¸­çš„æ•°ç»„å­˜å‚¨ç€ `StackAllocated` å¯¹è±¡çš„çœŸå®æ•°æ®ï¼Œè€Œ `data_heap` ä¿å­˜çš„æ˜¯æŒ‡é’ˆï¼ˆå³å†…å­˜åœ°å€ï¼‰ï¼š"

# â•”â•â•¡ 74a3ddb4-8af1-11eb-186e-4d80402adfcf
md"## å¯„å­˜å™¨ä¸ SIMD
ç°åœ¨æˆ‘ä»¬è¦å†æ¬¡æ›´æ–°ç®€åŒ–ç‰ˆçš„è®¡ç®—æœºæ¨¡å‹ã€‚CPU ä»…èƒ½æ“ä½œ**å¯„å­˜å™¨ï¼ˆregistersï¼‰**ä¸­çš„æ•°æ®ã€‚å¯„å­˜å™¨æ˜¯CPUå†…å¤§å°å›ºå®šï¼ˆä¾‹å¦‚8å­—èŠ‚ï¼‰çš„å°å‹æ•°æ®æ§½ï¼ˆslotsï¼‰ã€‚å¯„å­˜å™¨ç”¨äºä¿å­˜å•ä¸ªæ•°æ®ï¼Œæ¯”å¦‚ä¸€ä¸ªæ•´æ•°æˆ–æµ®ç‚¹æ•°ã€‚æ­£å¦‚æ±‡ç¼–ä»£ç é‚£èŠ‚æ‰€ç¤ºï¼Œæ¯æ¡æŒ‡ä»¤éƒ½ä¼šå¼•ç”¨ä¸€ä¸ªæˆ–ä¸¤ä¸ªå¯„å­˜å™¨ï¼Œå…¶ä¸­åŒ…å«äº†è¦æ“ä½œçš„æ•°æ®ï¼š

$$[CPU] â†” [REGISTERS] â†” [CACHE] â†” [RAM] â†” [DISK CACHE] â†” [DISK]$$

å¦‚æœè¦æ“ä½œå¤§äºå•ä¸ªå¯„å­˜å™¨çš„æ•°æ®ç»“æ„ï¼Œé‚£ä¹ˆæ•°æ®å¿…é¡»è¢«æ‹†åˆ†æˆå¤šä¸ªå¯„å­˜å™¨å¤§å°çš„å°æ•°æ®å—ã€‚ä¾‹å¦‚ï¼Œå½“åœ¨æˆ‘çš„ç”µè„‘ä¸Šå°†ä¸¤ä¸ª 128-bit æ•´æ•°ç›¸åŠ æ—¶ï¼š"

# â•”â•â•¡ 7a88c4ba-8af1-11eb-242c-a1813a9e6741
@code_native UInt128(5) + UInt128(11)

# â•”â•â•¡ 7d3fcbd6-8af1-11eb-0441-2f88a9d59966
md"""ç›®å‰æ²¡æœ‰å¯„å­˜å™¨èƒ½å¤Ÿç›´æ¥å¤„ç† 128-bit çš„æƒ…å†µã€‚é¦–å…ˆï¼Œä½¿ç”¨ `addq` æŒ‡ä»¤å°†ä½ä½çš„ 64 æ¯”ç‰¹åŠ èµ·æ¥ï¼Œå­˜å…¥ä¸€ä¸ªå¯„å­˜å™¨ã€‚ç„¶åï¼Œä½¿ç”¨ `adcq` æŒ‡ä»¤è®¡ç®—é«˜ä½æ¯”ç‰¹çš„åŠ æ³•ï¼Œè¯¥æŒ‡ä»¤ä¸ä»…å°†æ•°ç»„ç›¸åŠ ï¼Œè¿˜ä¼šä½¿ç”¨å‰ä¸€æŒ‡ä»¤çš„è¿›ä½æ¯”ç‰¹ã€‚æœ€åï¼Œä½¿ç”¨ `movq` æŒ‡ä»¤ä¸€æ¬¡å°†ç»“æœç§»åŠ¨ 64 ä½ã€‚

å¯„å­˜å™¨çš„å°å°ºå¯¸æ˜¯ CPU ååé‡çš„ç“¶é¢ˆä¹‹ä¸€ï¼šå®ƒä¸€æ¬¡æ€§ä»…èƒ½å¤„ç† 1 ä¸ªæ•´æ•°/æµ®ç‚¹æ•°ã€‚ä¸ºäº†é¿å…è¿™ç±»æƒ…å½¢ï¼Œç°ä»£ CPU åŒ…å«äº†ä¸“ç”¨çš„ 256 ä½å¯„å­˜å™¨ï¼ˆæ—§ CPU ä¸º 128 ä½ï¼Œæœ€æ–°çš„ CPU ä¸º 512 ä½ï¼‰ï¼Œæ•…èƒ½åŒæ—¶å¤„ç† 4 ä¸ª 64 ä½æ•´æ•°/æµ®ç‚¹æ•°ï¼Œæˆ–è€… 8 ä¸ª 32 ä½æ•´æ•°/æµ®ç‚¹æ•°ç­‰ç­‰ã€‚ä»¤äººè¿·æƒ‘çš„æ˜¯ï¼Œè¿™ç±»å®½å¯„å­˜å™¨ä¸­çš„æ•°æ®è¢«ç§°ä¸ºâ€œå‘é‡â€ã€‚CPU ä½¿ç”¨ç‰¹å®šçš„æŒ‡ä»¤å¯¹å‘é‡å®ç°å¤šç§ CPU æ“ä½œï¼Œå³ä¸€æ¡æŒ‡ä»¤æ“ä½œ 4 ä¸ª 64 ä½æ•´æ•°ã€‚è¿™è¢«ç§°ä¸ºâ€œå•æŒ‡ä»¤ï¼Œå¤šæ•°æ®ï¼ˆsingle instruction, multiple dataï¼‰â€ï¼Œ ç®€ç§°ä¸º **SIMD**ï¼Œæˆ–**å‘é‡åŒ–**ã€‚ç‰¹åˆ«åœ°ï¼Œ 4 ä¸ª 64 ä½çš„æ“ä½œå¹¶ä¸ä¸ä¸€ä¸ª 256 ä½çš„æ“ä½œç›¸åŒï¼Œä¾‹å¦‚ 4 ä¸ª 64 ä½æ•´æ•°ç›¸åŠ æ—¶ä¸å­˜åœ¨è¿›ä½ã€‚ä¸ä¹‹ç›¸åï¼Œä¸€ä¸ª 256 ä½å‘é‡çš„æ“ä½œç­‰ä»·äº 4 ä¸ªå•ç‹¬çš„ 64 ä½è¿ç®—ã€‚

å¯ä»¥é€šè¿‡ä¸‹é¢çš„ä¾‹å­è¯´æ˜è¿™ä¸€ç‚¹ï¼š"""

# â•”â•â•¡ 8c2ed15a-8af1-11eb-2e96-1df34510e773
md"""
åœ¨æ­¤å¤„ä»£ç ä¸­ï¼Œä¸¤ä¸ª 8x32 ä½çš„å‘é‡ä½¿ç”¨å•æ¡æŒ‡ä»¤ç›¸åŠ ã€‚å¯ä»¥çœ‹åˆ°ï¼ŒCPU ä½¿ç”¨äº†å•ä¸ª `vpaddd` ï¼ˆvector packed add doubleï¼ŒçŸ¢é‡èšåˆåŒç²¾åº¦åŠ æ³•ï¼‰æŒ‡ä»¤æ¥å¯¹ 8 ä¸ª 32 ä½æ•´æ•°åšåŠ æ³•ï¼Œå¯¹åº”çš„ç§»åŠ¨æŒ‡ä»¤ä¹Ÿå°±æ˜¯ `vmovdqu`ã€‚æ³¨æ„åˆ°ï¼Œå‘é‡åŒ–çš„ CPU æŒ‡ä»¤éƒ½ä»¥ `v` å¼€å¤´ã€‚

å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒSIMD å’Œå†…å­˜å¯¹é½çš„ç›¸äº’å½±å“ï¼šå¦‚æœä¸€ç³»åˆ— 256 ä½ï¼ˆ 32 å­—èŠ‚ï¼‰ SIMD åŠ è½½æœªå¯¹é½ï¼Œé‚£ä¹ˆå¯èƒ½æœ€å¤šä¼šæœ‰ä¸€åŠçš„åŠ è½½å°†è·¨è¶Šç¼“å­˜çº¿è¾¹ç•Œï¼Œè€Œä¸æ˜¯ä»…ä¸º 8 å­—èŠ‚çš„ 1/8ã€‚å› æ­¤ï¼Œåœ¨ä½¿ç”¨ SIMD æ—¶ï¼Œå¯¹é½æ˜¯ä¸€ä¸ªç›¸å½“ä¸¥é‡çš„é—®é¢˜ã€‚ç”±äºæ•°ç»„çš„èµ·å¤´æ€»æ˜¯å¯¹é½çš„ï¼Œæ‰€ä»¥è¿™å¯¹æ•°ç»„é€šå¸¸ä¸æ˜¯é—®é¢˜ã€‚ä½†æ˜¯ï¼Œåœ¨æ— æ³•ä¿è¯ä»å¯¹é½èµ·ç‚¹å¼€å§‹çš„æƒ…å†µä¸‹ï¼Œä¾‹å¦‚çŸ©é˜µè¿ç®—ï¼Œè¿™å¯èƒ½ä¼šäº§ç”Ÿæ˜¾è‘—çš„æ€§èƒ½å·®å¼‚ã€‚åœ¨åŒ…å« 512 ä½å¯„å­˜å™¨çš„æœ€æ–° CPU ä¸­ï¼Œé—®é¢˜æ›´ä¸ºä¸¥é‡ï¼Œå› ä¸º SIMD å¤§å°ä¸ç¼“å­˜çº¿å¤§å°ç›¸åŒï¼Œå› æ­¤å¦‚æœåˆå§‹çš„åŠ è½½å­˜åœ¨åç§»ï¼Œåˆ™æ‰€æœ‰çš„åŠ è½½éƒ½ä¼šå‘ç”Ÿåç§»ã€‚

64 ä½æ•´æ•°çš„ SIMD å‘é‡åŒ–å¯ä»¥å°† CPU ååé‡æé«˜ 4å€ï¼Œæ‰€ä»¥æ­¤ç§æ–¹æ³•åœ¨é«˜æ€§èƒ½ç¼–ç¨‹ä¸­å…·æœ‰å·¨å¤§çš„é‡è¦æ€§ã€‚ç¼–è¯‘å™¨ä¼šå°½å…¶æ‰€èƒ½åœ°è‡ªåŠ¨å‘é‡åŒ–æ“ä½œã€‚é‚£ä»€ä¹ˆå¯ä»¥é˜»æ­¢è¿™ç§è‡ªåŠ¨å‘é‡åŒ–å‘¢ï¼Ÿ

#### SIMD éœ€è¦ä¸ä¸­æ–­çš„å›ºå®šé•¿åº¦å¾ªç¯
å› ä¸ºå‘é‡åŒ–æ“ä½œä¸€æ¬¡å¤„ç†å¤šæ¡æ•°æ®ï¼Œå› æ­¤ä¸èƒ½åœ¨ä»»æ„ç‚¹ä¸­æ–­å¾ªç¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœèƒ½åœ¨ 1 ä¸ªæ—¶é’Ÿå‘¨æœŸå†…å¤„ç†4 ä¸ª 64 ä½æ•´æ•°ï¼Œé‚£ä¹ˆä¸å¯èƒ½åœ¨å¤„ç†äº† 3 ä¸ªæ•´æ•°ååœæ­¢ SIMD å¾ªç¯ã€‚å‡è®¾ä½ æœ‰å¦‚ä¸‹çš„å¾ªç¯ï¼š

```julia
for i in 1:8
    if foo()
        break
    end
    # do stuff with my_vector[i]
end
```

ç”±äºå­˜åœ¨ break è¯­å¥ï¼Œæ­¤å¤„çš„å¾ªç¯èƒ½å¤Ÿåœ¨ä»»æ„è¿­ä»£æ¬¡æ•°ç»“æŸã€‚å› æ­¤ï¼Œä»»ä½•åŠ è½½å¤šä¸ªæ•´æ•°çš„ SIMD æŒ‡ä»¤éƒ½èƒ½å¤„ç†å¾ªç¯ä¸­æ–­åçš„æ•°æ®ï¼Œå³æ°¸è¿œä¸åº”è¢«è¯»å–çš„æ•°æ®ã€‚è¿™æ˜¯é”™è¯¯çš„è¡Œä¸ºï¼Œå¹¶ä¸”ä¼šå¯¼è‡´ç¼–è¯‘å™¨ä¸èƒ½ä½¿ç”¨ SIMD æŒ‡ä»¤ã€‚

æ ¹æ®ç»éªŒæ¥çœ‹ï¼ŒSIMD éœ€è¦ï¼š
* å¾ªç¯é•¿åº¦é¢„å…ˆæŒ‡å®šï¼Œå› æ­¤åœæ­¢æ—¶æœºå¯çŸ¥
* ä»¥åŠå¾ªç¯ä½“å†…ä¸å­˜åœ¨åˆ†æ”¯ï¼ˆå³ if è¯­å¥ï¼‰

å®é™…ä¸Šï¼Œç”šè‡³è¾¹ç•Œæ£€æŸ¥ï¼Œå³æ£€æŸ¥ä½ çš„ç´¢å¼•æ˜¯å¦è¶…å‡ºå‘é‡çš„è¾¹ç•Œï¼Œéƒ½ä¼šå¯¼è‡´åˆ†æ”¯ã€‚æ¯•ç«Ÿï¼Œå¦‚æœä»£ç åœ¨ 3 æ¬¡è¿­ä»£åå¼•å‘è¶Šç•Œé”™è¯¯ï¼Œé‚£ä¹ˆå³ä½¿æ˜¯å•ä¸ª SIMD æŒ‡ä»¤éƒ½ä¼šå‡ºé”™ï¼å¦‚æœè¦å®ç° SIMD å‘é‡åŒ–ï¼Œé‚£ä¹ˆæ‰€æœ‰çš„è¾¹ç•Œæ£€æŸ¥éƒ½åº”è¯¥è¢«ç¦æ­¢æ‰ã€‚

å¹¸è¿çš„æ˜¯ï¼Œåœ¨æœ€æ–°ç‰ˆæœ¬çš„ Julia ä¸­ï¼Œç¼–è¯‘å™¨å·²ç»èªæ˜åˆ°å¯ä»¥æŒ‡å‡ºèƒ½å¤Ÿ SIMD çš„æ—¶æœºï¼Œå³ä½¿å­˜åœ¨è¾¹ç•Œæ£€æŸ¥ä¹Ÿå¯ä»¥ã€‚ 

ä¸ºäº†è¯´æ˜ SIMD çš„å½±å“ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªè¾“å…¥å‡½æ¥ä¸­æ–­å¾ªç¯ã€‚ç„¶åæ¯”è¾ƒä¸¤å‡½æ•°çš„é€Ÿåº¦ï¼Œä¸€ä¸ªæ˜¯å¯èƒ½ä¸­æ–­å¾ªç¯çš„å‡½æ•°ï¼Œå¦ä¸€ä¸ªæ˜¯ç¼–è¯‘å™¨çŸ¥é“ä¸å­˜åœ¨å¾ªç¯ä¸­æ–­å¹¶ä»¥SIMDæ–¹å¼æ‰§è¡Œçš„å‡½æ•°ã€‚"""

# â•”â•â•¡ 94182f88-8af1-11eb-207a-37083c1ead68
begin
	# The loop in the function breaks if pred(x[i])
	# returns `true`, and therefore cannot be SIMDd
    function sum_predicate(pred, x::Vector)
        n = zero(eltype(x))
        for i in eachindex(x)
			y = x[i]
			pred(y) && break
			n += y
        end
        return n
    end
end;

# â•”â•â•¡ aa3931fc-8af1-11eb-2f42-f582b8e639ad
md"""
åœ¨æˆ‘çš„ç”µè„‘ä¸Šï¼Œ SIMD ç‰ˆæœ¬çš„ä»£ç è¦æ¯”é SIMD ç‰ˆæœ¬çš„ä»£ç å¿«ä¸Š 10 å€ã€‚å•å‡­ SIMD èƒ½æä¾›çº¦ 4 å€çš„æ€§èƒ½æå‡ï¼ˆå› ä¸ºæˆ‘ä»¬å°†æ¯æ¬¡è¿­ä»£ 64 ä½æå‡åˆ°äº†æ¯æ¬¡è¿­ä»£ 256 ä½ï¼‰ã€‚å…¶ä½™çš„æå‡æ¥è‡ªäºæœªè€—æ—¶åšè¾¹ç•Œæ£€æŸ¥å’Œè‡ªåŠ¨å¾ªç¯å±•å¼€ï¼ˆåç»­å°†è¯´æ˜ï¼‰ï¼Œè¿™éƒ½æ˜¯é€šè¿‡ `@inbounds` å®ç°çš„ã€‚

#### SIMD needs a loop where loop order doesn't matter
SIMD can change the order in which elements in an array is processed. If the result of any iteration depends on any previous iteration such that the elements can't be re-ordered, the compiler will usually not SIMD-vectorize. Often when a loop won't auto-vectorize, it's due to subtleties in which data moves around in registers means that there will be some hidden memory dependency between elements in an array.

Imagine we want to sum some 64-bit integers in an array using SIMD. For simplicity, let's say the array has 8 elements, `A`, `B`, `C` ... `H`. In an ordinary non-SIMD loop, the additions would be done like so:

$$(((((((A + B) + C) + D) + E) + F) + G) + H)$$

Whereas when loading the integers using SIMD, four 64-bit integers would be loaded into one vector `<A, B, C, D>`, and the other four into another `<E, F, G, H>`. The two vectors would be added: `<A+E, B+F, C+G, D+H>`. After the loop, the four integers in the resulting vector would be added. So the overall order would be:

$$((((A + E) + (B + F)) + (C + G)) + (D + H))$$

Perhaps surprisingly, addition of floating point numbers can give different results depending on the order (i.e. float addition is not associative):
"""

# â•”â•â•¡ c01bf4b6-8af1-11eb-2f17-bfe0c93d48f9
begin
    x = eps(1.0) * 0.4
    1.0 + (x + x) == (1.0 + x) + x
end

# â•”â•â•¡ c80e05ba-8af1-11eb-20fc-235b45f2eb4b
md"for this reason, float addition will not auto-vectorize:"

# â•”â•â•¡ e3931226-8af1-11eb-0da5-fb3c1c22d12e
md"However, high-performance programming languages usually provide a command to tell the compiler it's alright to re-order the loop, even for non-associative loops. In Julia, this command is the `@simd` macro:"

# â•”â•â•¡ e793e300-8af1-11eb-2c89-e7bc1be249f0
function sum_simd(x::Vector)
    n = zero(eltype(x))
    # Here we add the `@simd` macro to allow SIMD of floats
    @inbounds @simd for i in eachindex(x)
        n += x[i]
    end
    return n
end;

# â•”â•â•¡ f0a4cb58-8af1-11eb-054c-03192285b5e2
md"""
Julia also provides the macro `@simd ivdep` which further tells the compiler that there are no memory-dependencies in the loop order. However, I *strongly discourage* the use of this macro, unless you *really* know what you're doing. In general, the compiler knows best when a loop has memory dependencies, and misuse of `@simd ivdep` can very easily lead to bugs that are hard to detect.
"""

# â•”â•â•¡ f5c28c92-8af1-11eb-318f-5fa059d8fd80
md"""
## Struct of arrays
If we create an array containing four `AlignmentTest` objects `A`, `B`, `C` and `D`, the objects will lie end to end in the array, like this:

    Objects: |      A        |       B       |       C       |        D      |
    Fields:  |   a   | b |c| |   a   | b |c| |   a   | b |c| |   a   | b |c| |
    Byte:     1               9              17              25              33

Note again that byte no. 8, 16, 24 and 32 are empty to preserve alignment, wasting memory.
Now suppose you want to do an operation on all the `.a` fields of the structs. Because the `.a` fields are scattered 8 bytes apart, SIMD operations are much less efficient (loading up to 4 fields at a time) than if all the `.a` fields were stored together (where 8 fields could fit in a 256-bit register). When working with the `.a` fields only, the entire 64-byte cache lines would be read in, of which only half, or 32 bytes would be useful. Not only does this cause more cache misses, we also need instructions to pick out the half of the data from the SIMD registers we need.

The memory structure we have above is termed an "array of structs," because, well, it is an array filled with structs. Instead we can strucure our 4 objects `A` to `D` as a "struct of arrays." Conceptually, it could look like:
"""

# â•”â•â•¡ fc2d2f1a-8af1-11eb-11a4-8700f94e866e
struct AlignmentTestVector
    a::Vector{UInt32}
    b::Vector{UInt16}
    c::Vector{UInt8}
end

# â•”â•â•¡ 007cd39a-8af2-11eb-053d-f584d68f7d2f
md"""
With the following memory layout for each field:

    Object: AlignmentTestVector
    .a |   A   |   B   |   C   |   D   |
    .b | A | B | C | D |
    .c |A|B|C|D|

Alignment is no longer a problem, no space is wasted on padding. When running through all the `a` fields, all cache lines contain full 64 bytes of relevant data, so SIMD operations do not need extra operations to pick out the relevant data:
"""

# â•”â•â•¡ 72fbb3ec-8ee8-11eb-3836-11092ef74e86
function Base.rand(::Type{AlignmentTest})
    AlignmentTest(rand(UInt32), rand(UInt16), rand(UInt8))
end;

# â•”â•â•¡ abb45d6a-8aef-11eb-37a4-7b10847b39b4
begin
    # Open a file
    function test_file(path)
        open(path) do file
            # Go to 1000'th byte of file and read it
            seek(file, 1000)
            read(file, UInt8)
        end
    end

    # Randomly access data N times
    function random_access(data::Vector{UInt}, N::Integer)
        n = rand(UInt)
        mask = length(data) - 1
        @inbounds for i in 1:N
            n = (n >>> 7) âŠ» data[n & mask + 1]
        end
        return n
    end
end;

# â•”â•â•¡ bff99828-8aef-11eb-107b-a5c67101c735
let
    data = rand(UInt, 2^24)
    @time test_file("../alen/src/main.rs")
    @time random_access(data, 1000000)
    nothing
end

# â•”â•â•¡ b73605ca-8ee4-11eb-1a0d-bb6678de91c6
begin
    @btime random_access($(rand(UInt, 1024)), 2^20) seconds=1
    @btime random_access($(rand(UInt, 2^24)), 2^20) seconds=1
    nothing
end

# â•”â•â•¡ ffca4c72-8aef-11eb-07ac-6d5c58715a71
function linear_access(data::Vector{UInt}, N::Integer)
    n = rand(UInt)
    mask = length(data) - 1
    for i in 1:N
        n = (n >>> 7) âŠ» data[(15 * i) & mask + 1]
    end
    return n
end;

# â•”â•â•¡ e71e4798-8ee4-11eb-3ea2-fdbbcdcf7410
let
    data = rand(UInt, 2^24)
    @btime random_access($data, 2^20) seconds=1
    @btime linear_access($data, 2^20) seconds=1
    nothing
end

# â•”â•â•¡ 18e8e4b6-8af0-11eb-2f17-2726f162e9b0
function alignment_test(data::Vector{UInt}, offset::Integer)
    # Jump randomly around the memory.
    n = rand(UInt)
    mask = (length(data) - 9) âŠ» 7
    GC.@preserve data begin # protect the array from moving in memory
        ptr = pointer(data)
        iszero(UInt(ptr) & 63) || error("Array not aligned")
        ptr += (offset & 63)
        for i in 1:4096
            n = (n >>> 7) âŠ» unsafe_load(ptr, (n & mask + 1) % Int)
        end
    end
    return n
end;

# â•”â•â•¡ 1f38f8c6-8ee5-11eb-1c01-f3706534a9cf
let
    data = rand(UInt, 256 + 8)
    @btime alignment_test($data, 0) seconds=1
    @btime alignment_test($data, 60) seconds=1
    nothing
end

# â•”â•â•¡ 3fae31a0-8af0-11eb-1ea8-7980e7875039
let
    memory_address = reinterpret(UInt, pointer(rand(1024)))
    @assert iszero(memory_address % 64) # should not error!
end

# â•”â•â•¡ 11c500e8-8ee2-11eb-3291-4382b60c5a2b
let
    data = rand(UInt, 2^10)
    show(stdout, MIME"text/plain"(), @benchmark increment($data) seconds=1)
    println('\n')
    show(stdout, MIME"text/plain"(), @benchmark increment!($data) seconds=1)
end

# â•”â•â•¡ 61ee9ace-8af1-11eb-34bd-c5af962c8d82
let
    Base.:+(x::Int, y::AllocatedInteger) = x + y.x
    Base.:+(x::AllocatedInteger, y::AllocatedInteger) = x.x + y.x

    data_stack = [StackAllocated(i) for i in rand(UInt16, 1000000)]
    data_heap = [HeapAllocated(i.x) for i in data_stack]

    @btime sum($data_stack) seconds=1
    @btime sum($data_heap) seconds=1
    nothing
end

# â•”â•â•¡ 6ba266f4-8af1-11eb-10a3-3daf6e473142
let
    data_stack = [StackAllocated(i) for i in rand(UInt16, 1)]
    data_heap = [HeapAllocated(i.x) for i in data_stack]

    println(rpad("First object of data_stack:", 36), data_stack[1])
    println(
        rpad("First data in data_stack array:", 36),
        unsafe_load(pointer(data_stack)),
        '\n'
    )

    println(rpad("First object of data_heap:", 36), data_heap[1])
    first_data = unsafe_load(Ptr{UInt}(pointer(data_heap)))
    println(rpad("First data in data_heap array:", 36), repr(first_data))
    println(
        "Data at address ",
        repr(first_data), ": ",
        unsafe_load(Ptr{HeapAllocated}(first_data))
    )
end

# â•”â•â•¡ 84c0d56a-8af1-11eb-30f3-d137b377c31f
let
    add_tuple(a, b) = a .+ b

    # Create a tuple of 8 32-bit integers.
    # could also have created 4 64-bit numbers etc.
    numbers = ntuple(i -> rand(UInt32), 8)
    @code_native debuginfo=:none dump_module=false add_tuple(numbers, numbers)
    nothing
end

# â•”â•â•¡ a0286cdc-8af1-11eb-050e-072acdd4f0a0
let
    # Make sure the vector is small so we don't time cache misses
    data = rand(UInt64, 4096)

	# For a function that always returns false, the compiler
	# knows it can never break, and so will SIMD
    @btime sum_predicate(Returns(false), $data) seconds=1

	# This function has a 1/2^64 risk of returning true;
	# while practically impossible, the compiler cannot
	# guarantee it won't break the loop, and so will not SIMD
    @btime sum_predicate(iszero, $data) seconds=1
    nothing
end

# â•”â•â•¡ cc99d9ce-8af1-11eb-12ec-fbd6df3becc8
let
    data = rand(Float64, 4096)
    @btime sum_predicate(Returns(false), $data) seconds=1
    @btime sum_predicate(iszero, $data) seconds=1
    nothing
end

# â•”â•â•¡ e8d2ec8e-8af1-11eb-2018-1fa4df5b47ad
let
    data = rand(Float64, 4096)
    @btime sum_predicate(Returns(false), $data) seconds=1
    @btime sum_simd($data) seconds=1
    nothing
end

# â•”â•â•¡ 054d848a-8af2-11eb-1f98-67f5d0b9f4ec
let
    N  = 1_000_000
    array_of_structs = [rand(AlignmentTest) for i in 1:N]
    struct_of_arrays = AlignmentTestVector(
        rand(UInt32, N),
        rand(UInt16, N),
        rand(UInt8, N)
    )

    @btime sum(x -> x.a, $array_of_structs) seconds=1
    @btime sum($struct_of_arrays.a) seconds=1
    nothing
end

# â•”â•â•¡ 0dfc5054-8af2-11eb-098d-35f4e69ae544
md"""
## Specialized CPU instructions

Most code makes use of only a score of simple CPU instructions like move, add, multiply, bitshift, and, or, xor, jumps, and so on. However, CPUs in the typical modern laptop support a *lot* of CPU instructions. Usually, if an operation is used heavily in consumer laptops, CPU manufacturers will add specialized instructions to speed up these operations. Depending on the hardware implementation of the instructions, the speed gain from using these instructions can be significant.

Julia only exposes a few specialized instructions, including:

* The number of set bits in an integer is effectively counted with the `popcnt` instruction, exposed via the `count_ones` function.
* The `tzcnt` instructions counts the number of trailing zeros in the bits an integer, exposed via the `trailing_zeros` function
* The order of individual bytes in a multi-byte integer can be reversed using the `bswap` instruction, exposed via the `bswap` function. This can be useful when having to deal with [endianness](https://en.wikipedia.org/wiki/Endianness).

The following example illustrates the performance difference between a manual implementation of the `count_ones` function, and the built-in version, which uses the `popcnt` instruction:
"""

# â•”â•â•¡ 126300a2-8af2-11eb-00ea-e76a979aef45
function manual_count_ones(x)
    n = 0
    while x != 0
        n += x & 1
        x >>>= 1
    end
    return n
end;

# â•”â•â•¡ 14e46866-8af2-11eb-0894-bba824f266f0
let
    data = rand(UInt, 10000)
    @btime sum(manual_count_ones, $data) seconds=1
    @btime sum(count_ones, $data) seconds=1
    nothing
end

# â•”â•â•¡ 1e7edfdc-8af2-11eb-1429-4d4220bad0f0
md"""
The timings you observe here will depend on whether your compiler is clever enough to realize that the computation in the first function can be expressed as a `popcnt` instruction, and thus will be compiled to that. On my computer, the compiler is not able to make that inference, and the second function achieves the same result more than 100x faster.

#### Call any CPU instruction
Julia makes it possible to call CPU instructions direcly. This is not generally advised, since not all your users will have access to the same CPU with the same instructions, and so your code will crash on users working on computers of different brands.

The latest CPUs contain specialized instructions for AES encryption and SHA256 hashing. If you wish to call these instructions, you can call Julia's backend compiler, LLVM, directly. In the example below, I create a function which calls the `vaesenc` (one round of AES encryption) instruction directly:
"""

# â•”â•â•¡ 25a47c54-8af2-11eb-270a-5b58c3aafe6e
begin
    # This is a 128-bit CPU "vector" in Julia
    const __m128i = NTuple{2, VecElement{Int64}}

    # Define the function in terms of LLVM instructions
    aesenc(a, roundkey) = ccall(
        "llvm.x86.aesni.aesenc", llvmcall, __m128i,
        (__m128i, __m128i), a, roundkey
    )
end;

# â•”â•â•¡ 2dc4f936-8af2-11eb-1117-9bc10e619ec6
md"(Thanks to Kristoffer Carlsson for [the example](http://kristofferc.github.io/post/intrinsics/)). We can verify it works by checking the assembly of the function, which should contain only a single `vaesenc` instruction, as well as the `retq` (return) and the `nopw` (do nothing, used as a filler to align the CPU instructions in memory) instruction:"

# â•”â•â•¡ 76a4e83c-8af2-11eb-16d7-75eaabcb21b6
@code_native debuginfo=:none dump_module=false aesenc(
	__m128i((1, 1)), __m128i((1, 1))
)

# â•”â•â•¡ 797264de-8af2-11eb-0cb0-adf3fbc95c90
md"""Algorithms which makes use of specialized instructions can be extremely fast. [In a blog post](https://mollyrocket.com/meowhash), the video game company Molly Rocket unveiled a new non-cryptographic hash function using AES instructions which reached unprecedented speeds."""

# â•”â•â•¡ 80179748-8af2-11eb-0910-2b825104159d
md"## Inlining
Consider the assembly of this function:"

# â•”â•â•¡ 36b723fc-8ee9-11eb-1b92-451b992acc0c
f() = error();

# â•”â•â•¡ 8af63980-8af2-11eb-3028-83a935bac0db
md"""
This code contains the `callq` instruction, which calls another function. A function call comes with some overhead depending on the arguments of the function and other things. While the time spent on a function call is measured in nanoseconds, it can add up if the function called is in a tight loop.

However, if we show the assembly of this function:
"""

# â•”â•â•¡ 50ab0cf6-8ee9-11eb-3e04-af5fef7f2850
call_plus(x) = x + 1;

# â•”â•â•¡ 93af6754-8af2-11eb-0fe6-216d76e683de
@code_native debuginfo=:none dump_module=false call_plus(1)

# â•”â•â•¡ a105bd68-8af2-11eb-31f6-3335b4fb0f08
md"""
The function `call_plus` calls `+`, and is compiled to a single `leaq` instruction (as well as some filler `retq` and `nopw`). But `+` is a normal Julia function, so `call_plus` is an example of one regular Julia function calling another. Why is there no `callq` instruction to call `+`?

The compiler has chosen to *inline* the function `+` into `call_plus`. That means that instead of calling `+`, it has copied the *content* of `+` directly into `call_plus`. The advantages of this is:
* There is no overhead from the function call
* There is no need to construct a `Tuple` to hold the arguments of the `+` function
* Whatever computations happens in `+` is compiled together with `call_plus`, allowing the compiler to use information from one in the other and possibly simplify some calculations.

So why aren't *all* functions inlined then? Inlining copies code, increases the size of it and consuming RAM. Furthermore, the *CPU instructions themselves* also needs to fit into the CPU cache (although CPU instructions have their own cache) in order to be efficiently retrieved. If everything was inlined, programs would be enormous and grind to a halt. Inlining is only an improvement if the inlined function is small.

Instead, the compiler uses heuristics (rules of thumb) to determine when a function is small enough for inlining to increase performance. These heuristics are not bulletproof, so Julia provides the macros `@noinline`, which prevents inlining of small functions (useful for e.g. functions that raises errors, which must be assumed to be called rarely), and `@inline`, which does not *force* the compiler to inline, but *strongly suggests* to the compiler that it ought to inline the function.

If code contains a time-sensitive section, for example an inner loop, it is important to look at the assembly code to verify that small functions in the loop is inlined. For example, in [this line in my kmer hashing code](https://github.com/jakobnissen/Kash.jl/blob/b9a6e71acf9651d3614f92d5d4b29ffd136bcb5c/src/kmersketch.jl#L41), overall minhashing performance drops by a factor of two if this `@inline` annotation is removed.

An extreme difference between inlining and no inlining can be demonstrated thus:
"""

# â•”â•â•¡ a843a0c2-8af2-11eb-2435-17e2c36ec253
begin
    @noinline noninline_poly(x) = x^3 - 4x^2 + 9x - 11
    inline_poly(x) = x^3 - 4x^2 + 9x - 11

    function time_function(F, x::AbstractVector)
        n = 0
        for i in x
            n += F(i)
        end
        return n
    end
end;

# â•”â•â•¡ b4d9cbb8-8af2-11eb-247c-d5b16e0de13f
let
    data = rand(UInt, 1024)
    @btime time_function(noninline_poly, $data) seconds=1
    @btime time_function(inline_poly, $data) seconds=1
    nothing
end

# â•”â•â•¡ bc0a2f22-8af2-11eb-3803-f54f84ddfc46
md"""
## Unrolling
Consider a function that sums a vector of 64-bit integers. If the vector's data's memory offset is stored in register `%r9`, the length of the vector is stored in register `%r8`, the current index of the vector in `%rcx` and the running total in `%rax`, the assembly of the inner loop could look like this:

```
L1:
    ; add the integer at location %r9 + %rcx * 8 to %rax
    addq   (%r9,%rcx,8), %rax

    ; increment index by 1
    addq   $1, %rcx

    ; compare index to length of vector
    cmpq   %r8, %rcx

    ; repeat loop if index is smaller
    jb     L1
```

For a total of 4 instructions per element of the vector. The actual code generated by Julia will be similar to this, but also incluce extra instructions related to bounds checking that are not relevant here (and of course will include different comments).

However, if the function is written like this:

```julia
function sum_vector(v::Vector{Int})
    n = 0
    i = 1
    for chunk in 1:div(length(v), 4)
        n += v[i + 0]
        n += v[i + 1]
        n += v[i + 2]
        n += v[i + 3]
        i += 4
    end
    return n
end
```

The result is obviously the same if we assume the length of the vector is divisible by four. If the length is not divisible by four, we could simply use the function above to sum the first $N - rem(N, 4)$ elements and add the last few elements in another loop. Despite the functionally identical result, the assembly of the loop is different and may look something like:

```
L1:
    addq   (%r9,%rcx,8), %rax
    addq   8(%r9,%rcx,8), %rax
    addq   16(%r9,%rcx,8), %rax
    addq   24(%r9,%rcx,8), %rax
    addq   $4, %rcx
    cmpq   %r8, %rcx
    jb     L1
```

For a total of 7 instructions per 4 additions, or 1.75 instructions per addition. This is less than half the number of instructions per integer! The speed gain comes from simply checking less often when we're at the end of the loop. We call this process *unrolling* the loop, here by a factor of four. Naturally, unrolling can only be done if we know the number of iterations beforehand, so we don't "overshoot" the number of iterations. Often, the compiler will unroll loops automatically for extra performance, but it can be worth looking at the assembly. For example, this is the assembly for the innermost loop generated on my computer for `sum([1])`:

    L144:
        vpaddq  16(%rcx,%rax,8), %ymm0, %ymm0
        vpaddq  48(%rcx,%rax,8), %ymm1, %ymm1
        vpaddq  80(%rcx,%rax,8), %ymm2, %ymm2
        vpaddq  112(%rcx,%rax,8), %ymm3, %ymm3
        addq    $16, %rax
        cmpq    %rax, %rdi
        jne L144

Where you can see it is both unrolled by a factor of four, and uses 256-bit SIMD instructions, for a total of 128 bytes, 16 integers added per iteration, or 0.44 instructions per integer.

Notice also that the compiler chooses to use 4 different `ymm` SIMD registers, `ymm0` to `ymm3`, whereas in my example assembly code, I just used one register `rax`. This is because, if you use 4 independent registers, then you don't need to wait for one `vpaddq` to complete (remember, it had a ~3 clock cycle latency) before the CPU can begin the next.

The story for unrolling is similar to that for SIMD: The compiler will only unroll a loop if it can tell _for sure_ that it will not overshoot the number of iterations. For example, compare the two following functions:
"""

# â•”â•â•¡ f0bc1fdc-8ee9-11eb-2916-d71e1cf36375
let
    data = fill(false, 2^20)

    # any: Stops as soon as it finds a `true`
    @btime any($data) seconds=1

    # foldl: Loops over all values in the array
    @btime foldl(|, $data) seconds=1

    data[1] = true
    @btime any($data) seconds=1
    @btime foldl(|, $data) seconds=1
    nothing
end

# â•”â•â•¡ 36a2872e-8eeb-11eb-0999-4153ced71678
md"""
The _first_ function stops and returns as soon as it finds a `true` value - but this break in the loop disables SIMD and unrolling. The _second_ function continues throughout the entire array, even if the very first value is `true`. While this enables SIMD and unrolling, it's obviously wasteful if it sees a `true` right in the beginning. Hence, the first is better when we expect to see the first `true` before around 1/4th of the way though the array, the latter better otherwise.

We can create a compromise by manually unrolling. In the functions below, `check128` checks 128 entries using `inbounds`, without stopping underway to check if it's found a `true`, and is thus unrolled and SIMDd. `unroll_compromise` then uses `check128`, but breaks out of the loop as soon as it finds a `true.`
"""

# â•”â•â•¡ 9ca70cfc-8eeb-11eb-361b-b929089ca109
begin
    @inline function check128(data, i)
        n = false
        @inbounds for j in 0:127
            n |= data[i+j]
        end
        n
    end

    function unroll_compromise(data)
        found = false
        i = 1
        while !found & (i â‰¤ length(data))
            check128(data, i) && return true
            i += 128
        end
        return false
    end
end;

# â•”â•â•¡ d4a43094-8eeb-11eb-106f-3b54253aa663
let
    data = fill(false, 2^20)
    @btime foldl(|, $data) seconds=1
    @btime unroll_compromise($data) seconds=1

    data[1] = true
    @btime any($data) seconds=1
    @btime unroll_compromise($data) seconds=1
    nothing
end

# â•”â•â•¡ 270950ac-8eed-11eb-365d-df9d36d090bc
md"""
We see excellent performance for both arrays with no `trues`, and for the one with a `true` right in the beginning.

Unfortunately, I'm not aware of any way to automatically generate this kind of unrolling, where you want a compromise between unrolling smaller chunks, and including branches in between each chunk. Perhaps in the future, this desire can be communicated to the compiler, such that the optimal code is automatically generated.
"""

# â•”â•â•¡ c36dc5f8-8af2-11eb-3f35-fb86143a54d2
md"""
## Avoid unpredicable branches
As mentioned previously, CPU instructions take multiple cycles to complete, but may be queued into the CPU before the previous instruction has finished computing. So what happens when the CPU encounters a branch (i.e. a jump instruction)? It can't know which instruction to queue next, because that depends on the instruction that it just put into the queue and which has yet to be executed.

Modern CPUs make use of *branch prediction*. The CPU has a *branch predictor* circuit, which guesses the correct branch based on which branches were recently taken. In essense, the branch predictor attempts to learn simple patterns in which branches are taken in code, while the code is running. After queueing a branch, the CPU immediately queues instructions from whatever branch predicted by the branch predictor. The correctness of the guess is verified later, when the queued branch is being executed. If the guess was correct, great, the CPU saved time by guessing. If not, the CPU has to empty the pipeline and discard all computations since the initial guess, and then start over. This process causes a delay of a few nanoseconds.

For the programmer, this means that the speed of an if-statement depends on how easy it is to guess. If it is trivially easy to guess, the branch predictor will be correct almost all the time, and the if statement will take no longer than a simple instruction, typically 1 clock cycle. In a situation where the branching is random, it will be wrong about 50% of the time, and each misprediction may cost many clock cycles.

Branches caused by loops are among the easiest to guess. If you have a loop with 1000 elements, the code will loop back 999 times and break out of the loop just once. Hence the branch predictor can simply always predict "loop back", and get a 99.9% accuracy.

We can demonstrate the performance of branch misprediction with a simple function:
"""

# â•”â•â•¡ c96f7f50-8af2-11eb-0513-d538cf6bc619
# Copy all odd numbers from src to dst.
function copy_odds_branches!(dst::Vector{T}, src::Vector{T}) where {T <: Integer}
    write_index = 1
    @inbounds for i in eachindex(src) # <--- this branch is trivially easy to predict
        v = src[i]
        if isodd(v)  # <--- this is the branch we want to predict
            dst[write_index] = v
            write_index += 1
        end
    end
    return dst
end;

# â•”â•â•¡ cf90c600-8af2-11eb-262a-2763ae29b428
let
    dst = rand(UInt32, 2^18)
    src_random = rand(UInt32, 2^18)
    src_all_odd = [(2*i+1) % UInt32 for i in src_random]
    @btime copy_odds_branches!($dst, $src_random) seconds=1
    @btime copy_odds_branches!($dst, $src_all_odd) seconds=1
    nothing
end

# â•”â•â•¡ d53422a0-8af2-11eb-0417-b9740c4a571c
md"""
In the first case, the integers are random, and about half the branches will be mispredicted causing delays. In the second case, the branch is always taken, the branch predictor is quickly able to pick up the pattern and will reach near 100% correct prediction. As a result, on my computer, the latter is around 8x faster.

Note that if you use smaller vectors and repeat the computation many times, as the `@btime` macro does, the branch predictor is able to learn the pattern of the small random vectors by heart, and will reach much better than random prediction. This is especially pronounced in the most modern CPUs (and in particular the CPUs sold by AMD, I hear) where the branch predictors have gotten much better. This "learning by heart" is an artifact of the loop in the benchmarking process. You would not expect to run the exact same computation repeatedly on real-life data:
"""

# â•”â•â•¡ dc5b9bbc-8af2-11eb-0197-9b5da5087f0d
let
    src_random = rand(UInt32, 128)
    dst = similar(src_random)
    src_all_odd = [(2i+1) % UInt32 for i in src_random]

    @btime copy_odds_branches!($dst, $src_random) seconds=1
    @btime copy_odds_branches!($dst, $src_all_odd) seconds=1
    nothing
end

# â•”â•â•¡ e735a302-8af2-11eb-2ce7-01435b60fdd9
md"""
Because branches are very fast if they are predicted correctly, highly predictable branches caused by error checks are not of much performance concern, assuming that the code essensially never errors. Hence a branch like bounds checking is very fast. You should only remove bounds checks if absolutely maximal performance is critical, or if the bounds check happens in a loop which would otherwise SIMD-vectorize.

If branches cannot be easily predicted, it is often possible to re-phrase the function to avoid branches all together. For example, in the `copy_odds!` example above, we could instead write it like so:
"""

# â•”â•â•¡ eb158e60-8af2-11eb-2227-59d6404e3335
function copy_odds_branchless!(dst::Vector{T}, src::Vector{T}) where {T <: Integer}
    write_index = 1
    @inbounds for i in eachindex(src)
        v = src[i]
        dst[write_index] = v
        write_index += isodd(v)
    end
    return dst
end;

# â•”â•â•¡ ee579dca-8af2-11eb-140f-a96778b7b39f
let
    dst = rand(UInt32, 2^18)
    src_random = rand(UInt32, 2^18)
    src_all_odd = [(2*i+1) % UInt32 for i in src_random]
    @btime copy_odds_branchless!($dst, $src_random) seconds=1
    @btime copy_odds_branchless!($dst, $src_all_odd) seconds=1
    nothing
end

# â•”â•â•¡ f969eed2-8af2-11eb-1e78-5b322a7f4ebd
md"""
Which contains no other branches than the one caused by the loop itself (which is easily predictable), and results in speeds slightly worse than the perfectly predicted one, but much better for random data.

The compiler will often remove branches in your code when the same computation can be done using other instructions. When the compiler fails to do so, Julia offers the `ifelse` function, which sometimes can help elide branching.
"""

# â•”â•â•¡ 72e1b146-8c1c-11eb-2c56-b1342271c2f6
md"""
## Be aware of memory dependencies

Thinking about it more deeply, why *is* the perfectly predicted example above faster than the solution that avoids having that extra branch there at all?

Let's look at the assembly code. Here, I've just cut out the assembly for the loop (since almost all time is spent there)

For the branch-ful version, we have:
```julia
1 L48:
2     incq	%rsi
3     cmpq	%rsi, %r9
4     je	L75
5 L56:
6     movq	(%rdx,%rsi,8), %rcx
7     testb	$1, %cl
8     je	L48
9     movq	%rcx, -8(%r8,%rdi,8)
10	incq	%rdi
11	jmp	L48
```

And for the branch-less, we have:
```julia
1 L48:
2	movq	(%r9,%rcx,8), %rdx
3	incq	%rcx
4	movq	%rdx, -8(%rsi,%rdi,8)
5	andl	$1, %edx
6	addq	%rdx, %rdi
7	cmpq	%rcx, %r8
8	jne	L48
```

The branch-ful executes 9 instructions per iteration (remember, all iterations had uneven numbers), whereas the branch-less executes only 7. Looking at the table for how long instructions take, you will find all these instructions are fast. So what gives?

To understand what is happening, we need to go a little deeper into the CPU. In fact, the CPU does not execute CPU instructions in a linear fashion as the assembly code would have you believe. Instead, a more accurate (but still simplified) picture is the following:

1. The CPU reads in CPU instructions. It then on-the-fly translates these CPU instructions to a set of even lower-level instructions called _micro-operations_ or _Âµops_. The important difference between Âµops and CPU instructions is that while only a few different registers can be referred to by the instructions, the actual processor has many more registers, which can be addressed by Âµops. Code written with Âµops is called _microcode_.

2. This microcode is loaded into an internal array called the *reorder buffer* for storage. A CPU may hold more than 200 instructions in the reorder buffer at a time. The purpose of this storage is to allow execution of microcode in a highly parallel way. The code is then sent to execution in bulk.

3. Finally, results from the reorder buffer is then shipped out to memory in the correct order.

The existance of a re-order buffer has two important implications (that I know about) for how you should think about your code:

First, your code is executed in large chunks often in parallel, not necessarily in the same order as it was loaded in. Therefore, _a program with more, slower CPU instructions can be faster than a program with fewer, faster instructions_, if the former program manages to execute more of them in parallel.

Second, branch prediction (as discussed in the previous section) does not happen just for the upcoming branch, but instead for a large amount of future branches, simultaneously.

When visualizing how the code of the small `copy_odds_branches!` loop above is executed, you may imagine that the branch predictor predicts all branches, say, 6 iterations of the loop into the future, loads the microcode of all 6 future iterations into the reorder buffer, executes them all in parallel, and _then_ verifies - still in parallel - that its branches were guessed correctly.

 Indicentally, this bulk processing is why a branch mispredict is so bad for performance - if a branch turns out to be mispredicted, all the work in the reorder buffer must be scrapped, the and the CPU must start over with fetching new instructions, compile them to microcode, fill the buffer et cetera.

Let's think about the implications re-order buffer for a moment. Other than creating hard-to-predict branches, what kind of code can re write that messes up that workflow for the CPU?

What if we do this?
"""

# â•”â•â•¡ 7732b6d8-8dab-11eb-0bc2-19690386ec27
function read_indices(dst::Vector{T}, src::Vector{T}) where {T <: Integer}
    i = 1
    while i â‰¤ lastindex(src) - 1
        i = src[i] + 1
        dst[i] = i
    end
    return dst
end;

# â•”â•â•¡ 29463b02-8dab-11eb-0bf5-23a3f4075b32
let
    dst = rand(UInt32, 2^18)
    src = UInt32.(eachindex(dst))
    @btime read_indices($dst, $src) seconds=1
    nothing
end

# â•”â•â•¡ a5d93434-8dac-11eb-34bf-91061089f0ef
md"""
If you think about it, `read_indices` does strictly less work than any of the `copy_odds` functions. It doesn't even check if the numbers it copies are odd. Yet it's more than three times slower than `copy_odds_branches`!

The difference is *memory dependencies*. We humans, seeing that the input data is simply a range of numbers, can tell _precisely_ what the function should do at every iteration: Simply copy the next number over. But the compiler _can't_ predict what the next number it loads will be, and therefore where it needs to store the loaded number. We say that the code has a memory dependency on the number it loads from `src`.

In that case, the reorder buffer is of no use. All the instructions get loaded in, but are simply kept idle in the reorder buffer, because they simply *cannot* be executed until it's "their turn".

Going back to the original example, that is why the perfectly predicted `copy_odds_branches!` performs better than `code_odds_branchless!`. Even though the latter has fewer instructions, it has a memory dependency: The index of `dst` where the odd number gets stored to depends on the last loop iteration. So fewer instructions can be executed at a time compared to the former function, where the branch predictor predicts several iterations ahead and allow for the parallel computation of multiple iterations.
"""

# â•”â•â•¡ 0b6d234e-8af3-11eb-1ba9-a1dcf1497785
md"""
## Variable clock speed

A modern laptop CPU optimized for low power consumption consumes roughly 25 watts of power on a chip as small as a stamp (and thinner than a human hair). Without proper cooling, this will cause the temperature of the CPU to skyrocket and melting the plastic of the chip, destroying it. Typically, CPUs have a maximal operating temperature of about 100 degrees C. Power consumption, and therefore heat generation, depends among many factors on clock speed, higher clock speeds generate more heat.

Modern CPUs are able to adjust their clock speeds according to the CPU temperature to prevent the chip from destroying itself. Often, CPU temperature will be the limiting factor in how quick a CPU is able to run. In these situations, better physical cooling for your computer translates directly to a faster CPU. Old computers can often be revitalized simply by removing dust from the interior, and replacing the cooling fans and [CPU thermal paste](https://en.wikipedia.org/wiki/Thermal_grease)!

As a programmer, there is not much you can do to take CPU temperature into account, but it is good to know. In particular, variations in CPU temperature often explain observed difference in performance:

* CPUs usually work fastest at the beginning of a workload, and then drop in performance as it reaches maximal temperature
* SIMD instructions usually require more power than ordinary instructions, generating more heat, and lowering the clock frequency. This can offset some performance gains of SIMD, but SIMD will nearly always be more efficient when applicable. One exception is the relatively recent 512-bit SIMD instructions. In current (2021) CPUs, these instructions draw so much power that the resulting clock frequency lowering actually leads to overall performance decrease for some workloads. This problem will probably be solved in the near future, either by the power draw begin reduced, by consumer chips abandoning 512-bit SIMD, or by compilers refusing to compile to these instructions.
"""

# â•”â•â•¡ 119d269c-8af3-11eb-1fdc-b7ac75b89cf2
md"""
## Multithreading
In the bad old days, CPU clock speed would increase every year as new processors were brought onto the market. Partially because of heat generation, this acceleration slowed down once CPUs hit the 3 GHz mark. Now we see only minor clock speed increments every processor generation. Instead of raw speed of execution, the focus has shifted on getting more computation done per clock cycle. CPU caches, CPU pipelining (i.e. the entire re-order buffer "workflow"), branch prediction and SIMD instructions are all important contibutions in this area, and have all been covered here.

Another important area where CPUs have improved is simply in numbers: Almost all CPU chips contain multiple smaller CPUs, or *cores* inside them. Each core has their own small CPU cache, and does computations in parallel. Furthermore, many CPUs have a feature called *hyper-threading*, where two *threads* (i.e. streams of instructions) are able to run on each core. The idea is that whenever one process is stalled (e.g. because it experiences a cache miss or a branch misprediction), the other process can continue on the same core. The CPU "pretends" to have twice the amount of processors.

Hyperthreading only really matters when your threads are sometimes prevented from doing work. Besides CPU-internal causes like cache misses, a thread can also be paused because it is waiting for an external resource like a webserver or data from a disk. If you are writing a program where some threads spend a significant time idling, the core can be used by the other thread, and hyperthreading can show its value.

Let's see our first parallel program in action. First, we need to make sure that Julia actually was started with the correct number of threads. To do this, start Julia with the `-t` option - e.g. `-t 8` for 8 threads. I have set Julia to have 4 threads:
"""

# â•”â•â•¡ 1886f60e-8af3-11eb-2117-eb0014d2fca1
Threads.nthreads()

# â•”â•â•¡ 1a0e2998-8af3-11eb-031b-a3448fd65041
# Spend about half the time waiting, half time computing
function half_asleep(start::Bool)
    a, b = 1, 0
    for iteration in 1:5
        start && sleep(0.1)
		t1 = time()
		while time() - t1 < 0.1
			for i in 1:100000
            	a, b = a + b, a
			end
        end
        start || sleep(0.1)
    end
    return a
end;

# â•”â•â•¡ 1ecf434a-8af3-11eb-3c49-cb21c6a80bfc
function parallel_sleep(n_jobs)
    jobs = []
    for job in 1:n_jobs
        push!(jobs, Threads.@spawn half_asleep(isodd(job)))
    end
    return sum(fetch, jobs)
end;

# â•”â•â•¡ 2192c228-8af3-11eb-19d8-81db4f3c0d81
let
    parallel_sleep(1); # run once to compile it
    for njobs in (1, 4, 8, 16, 32)
        @time parallel_sleep(njobs);
    end
end

# â•”â•â•¡ 2d0bb0a6-8af3-11eb-384d-29fbb0f66f24
md"""
You can see that with this task, my computer can run 8 jobs in parallel almost as fast as it can run 1. But 16 jobs takes much longer. This is because 4 can run at the same time, and 4 more can sleep for a total of 8 concurrent jobs.

For CPU-constrained programs, the core is kept busy with only one thread, and there is not much to do as a programmer to leverage hyperthreading. Actually, for the most optimized programs, it usually leads to better performance to *disable* hyperthreading. Most workloads are not that optimized and can really benefit from hyperthreading, however.

#### Parallelizability
Multithreading is more difficult that any of the other optimizations, and should be one of the last tools a programmer reaches for. However, it is also an impactful optimization. Scientific compute clusters usually contain many (e.g. hundreds, or thousands) of CPUs with tens of CPU cores each, offering a massive potential speed boost ripe for picking.

A prerequisite for efficient use of multithreading is that your computation is able to be broken up into multiple chunks that can be worked on independently. Luckily the majority of compute-heavy tasks (at least in my field of work, bioinformatics), contain sub-problems that are *embarassingly parallel*. This means that there is a natural and easy way to break it into sub-problems that can be processed independently. For example, if a certain __independent__ computation is required for 100 genes, it is natural to use one thread for each gene. The size of the problem is also important. There is a small overhead involved with spawning (creating) a thread, and fetching the result from the computation of a thread. Therefore, for it to pay off, each thread should have a task that takes at least a few microseconds to complete.

Let's have an example of a small embarrasingly parallel problem. We want to construct a [Julia set](https://en.wikipedia.org/wiki/Julia_set). Julia sets are named after Gaston Julia, and have nothing to do with the Julia language. Julia sets are (often) fractal sets of complex numbers. By mapping the real and complex component of the set's members to the X and Y pixel value of a screen, one can generate the LSD-trippy images associated with fractals.

The Julia set I create below is defined thus: We define a function $f(z) = z^2 + C$, where $C$ is some constant. We then record the number of times $f$ can be applied to any given complex number $z$ before $|z| > 2$. The number of iterations correspond to the brightness of one pixel in the image. We simply repeat this for a range of real and imaginary values in a grid to create an image.

First, let's see a non-parallel solution:
"""

# â•”â•â•¡ 316e5074-8af3-11eb-256b-c5b212f7e0d3
begin
    const SHIFT = Complex{Float32}(-0.221, -0.713)

    f(z::Complex) = z^2 + SHIFT

    "Set the brightness of a particular pixel represented by a complex number"
    function mandel(z)
        n = 0
        while ((abs2(z) < 4) & (n < 255))
            n += 1
            z = f(z)
        end
        return n
    end

    "Set brightness of pixels in one column of pixels"
    function fill_column!(M::Matrix, x, real)
        for (y, im) in enumerate(range(-1.0f0, 1.0f0, length=size(M, 1)))
            M[y, x] = mandel(Complex{Float32}(real, im))
        end
    end

    "Create a Julia fractal image"
    function julia_single_threaded()
        M = Matrix{UInt8}(undef, 5000, 5000)
        for (x, real) in enumerate(range(-1.0f0, 1.0f0, length=size(M, 2)))
            fill_column!(M, x, real)
        end
        return M
    end
end;

# â•”â•â•¡ 37cd1f1c-8ee9-11eb-015c-ade9efc27708
@code_native debuginfo=:none dump_module=false f()

# â•”â•â•¡ 39a85a58-8af3-11eb-1334-6f50ed9acd31
@time julia_single_threaded();

# â•”â•â•¡ 3e83981a-8af3-11eb-3c87-77797adb7e1f
md"That took around 2 seconds on my computer. Now for a parallel one:"

# â•”â•â•¡ 3e1c4090-8af3-11eb-33d0-b9c299fef20d
begin
    function recursive_fill_columns!(M::Matrix, cols::UnitRange)
        F, L = first(cols), last(cols)
        # If only one column, fill it using fill_column!
        if F == L
            r = range(-1.0f0,1.0f0,length=size(M, 1))[F]
            fill_column!(M, F, r)
        # Else divide the range of columns in two, spawning a new task for each half
        else
            mid = div(L+F,2)
            p = Threads.@spawn recursive_fill_columns!(M, F:mid)
            recursive_fill_columns!(M, mid+1:L)
            wait(p)
        end
    end

    function julia_multi_threaded()
        M = Matrix{UInt8}(undef, 5000, 5000)
        recursive_fill_columns!(M, 1:size(M, 2))
        return M
    end
end;

# â•”â•â•¡ 4be905b4-8af3-11eb-0344-dbdc7e94ddf3
@time julia_multi_threaded();

# â•”â•â•¡ 4e8f6cb8-8af3-11eb-1746-9384995d7022
md"""
This is almost exactly 4 times as fast! With 4 threads, this is close to the best case scenario, only possible for near-perfect embarrasingly parallel tasks.

Despite the potential for great gains, in my opinion, multithreading should be one of the last resorts for performance improvements, for three reasons:

1. Implementing multithreading is harder than other optimization methods in many cases. In the example shown, it was very easy. In a complicated workflow, it can get messy quickly.
2. Multithreading can cause hard-to-diagnose and erratic bugs. These are almost always related to multiple threads reading from, and writing to the same memory. For example, if two threads both increment an integer with value `N` at the same time, the two threads will both read `N` from memory and write `N+1` back to memory, where the correct result of two increments should be `N+2`! Infuriatingly, these bugs appear and disappear unpredictably, since they are causing by unlucky timing. These bugs of course have solutions, but it is tricky subject outside the scope of this document.
3. Finally, achieving performance by using multiple threads is really achieving performance by consuming more resources, instead of gaining something from nothing. Often, you pay for using more threads, either literally when buying cloud compute time, or when paying the bill of increased electricity consumption from multiple CPU cores, or metaphorically by laying claim to more of your users' CPU resources they could use somewhere else. In contrast, more *efficent* computation costs nothing.
"""

# â•”â•â•¡ 54d2a5b8-8af3-11eb-3273-85d551fceb7b
md"""
## GPUs
So far, we've covered only the most important kind of computing chip, the CPU. But there are many other kind of chips out there. The most common kind of alternative chip is the *graphical processing unit* or GPU.

As shown in the above example with the Julia set, the task of creating computer images are often embarassingly parallel with an extremely high degree of parallelizability. In the limit, the value of each pixel is an independent task. This calls for a chip with a high number of cores to do effectively. Because generating graphics is a fundamental part of what computers do, nearly all commercial computers contain a GPU. Often, it's a smaller chip integrated into the motherboard (*integrated graphics*, popular in small laptops). Other times, it's a large, bulky card.

GPUs have sacrificed many of the bells and whistles of CPUs covered in this document such as specialized instructions, SIMD and branch prediction. They also usually run at lower frequencies than CPUs. This means that their raw compute power is many times slower than a CPU. To make up for this, they have a high number of cores. For example, the high-end gaming GPU NVIDIA RTX 2080Ti has 4,352 cores. Hence, some tasks can experience 10s or even 100s of times speedup using a GPU. Most notably for scientific applications, matrix and vector operations are highly parallelizable.

Unfortunately, the laptop I'm writing this document on has only integrated graphics, and there is not yet a stable way to interface with integrated graphics using Julia, so I cannot show examples.

There are also more esoteric chips like TPUs (explicitly designed for low-precision tensor operations common in deep learning) and ASICs (an umbrella term for highly specialized chips intended for one single application). At the time of writing, these chips are uncommon, expensive, poorly supported and have limited uses, and are therefore not of any interest for non-computer science researchers.
"""

# â•”â•â•¡ 00000000-0000-0000-0000-000000000001
PLUTO_PROJECT_TOML_CONTENTS = """
[deps]
BenchmarkTools = "6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf"
PlutoUI = "7f904dfe-b85e-4ff6-b463-dae2292396a8"

[compat]
BenchmarkTools = "~1.1.3"
PlutoUI = "~0.7.39"
"""

# â•”â•â•¡ 00000000-0000-0000-0000-000000000002
PLUTO_MANIFEST_TOML_CONTENTS = """
# This file is machine-generated - editing it directly is not advised

[[AbstractPlutoDingetjes]]
deps = ["Pkg"]
git-tree-sha1 = "8eaf9f1b4921132a4cff3f36a1d9ba923b14a481"
uuid = "6e696c72-6542-2067-7265-42206c756150"
version = "1.1.4"

[[ArgTools]]
uuid = "0dad84c5-d112-42e6-8d28-ef12dabb789f"
version = "1.1.1"

[[Artifacts]]
uuid = "56f22d72-fd6d-98f1-02f0-08ddc0907c33"

[[Base64]]
uuid = "2a0f44e3-6c83-55bd-87e4-b1978d98bd5f"

[[BenchmarkTools]]
deps = ["JSON", "Logging", "Printf", "Statistics", "UUIDs"]
git-tree-sha1 = "42ac5e523869a84eac9669eaceed9e4aa0e1587b"
uuid = "6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf"
version = "1.1.4"

[[ColorTypes]]
deps = ["FixedPointNumbers", "Random"]
git-tree-sha1 = "eb7f0f8307f71fac7c606984ea5fb2817275d6e4"
uuid = "3da002f7-5984-5a60-b8a6-cbb66c0b333f"
version = "0.11.4"

[[CompilerSupportLibraries_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "e66e0078-7015-5450-92f7-15fbd957f2ae"
version = "0.5.2+0"

[[Dates]]
deps = ["Printf"]
uuid = "ade2ca70-3891-5945-98fb-dc099432e06a"

[[Downloads]]
deps = ["ArgTools", "FileWatching", "LibCURL", "NetworkOptions"]
uuid = "f43a241f-c20a-4ad4-852c-f6b1247861c6"
version = "1.6.0"

[[FileWatching]]
uuid = "7b1f6079-737a-58dc-b8bc-7a2ca5c1b5ee"

[[FixedPointNumbers]]
deps = ["Statistics"]
git-tree-sha1 = "335bfdceacc84c5cdf16aadc768aa5ddfc5383cc"
uuid = "53c48c17-4a7d-5ca2-90c5-79b7896eea93"
version = "0.8.4"

[[Hyperscript]]
deps = ["Test"]
git-tree-sha1 = "8d511d5b81240fc8e6802386302675bdf47737b9"
uuid = "47d2ed2b-36de-50cf-bf87-49c2cf4b8b91"
version = "0.0.4"

[[HypertextLiteral]]
deps = ["Tricks"]
git-tree-sha1 = "c47c5fa4c5308f27ccaac35504858d8914e102f9"
uuid = "ac1192a8-f4b3-4bfe-ba22-af5b92cd3ab2"
version = "0.9.4"

[[IOCapture]]
deps = ["Logging", "Random"]
git-tree-sha1 = "f7be53659ab06ddc986428d3a9dcc95f6fa6705a"
uuid = "b5f81e59-6552-4d32-b1f0-c071b021bf89"
version = "0.2.2"

[[InteractiveUtils]]
deps = ["Markdown"]
uuid = "b77e0a4c-d291-57a0-90e8-8db25a27a240"

[[JSON]]
deps = ["Dates", "Mmap", "Parsers", "Unicode"]
git-tree-sha1 = "3c837543ddb02250ef42f4738347454f95079d4e"
uuid = "682c06a0-de6a-54ab-a142-c8b1cf79cde6"
version = "0.21.3"

[[LibCURL]]
deps = ["LibCURL_jll", "MozillaCACerts_jll"]
uuid = "b27032c2-a3e7-50c8-80cd-2d36dbcbfd21"
version = "0.6.3"

[[LibCURL_jll]]
deps = ["Artifacts", "LibSSH2_jll", "Libdl", "MbedTLS_jll", "Zlib_jll", "nghttp2_jll"]
uuid = "deac9b47-8bc7-5906-a0fe-35ac56dc84c0"
version = "7.84.0+0"

[[LibGit2]]
deps = ["Base64", "NetworkOptions", "Printf", "SHA"]
uuid = "76f85450-5226-5b5a-8eaa-529ad045b433"

[[LibSSH2_jll]]
deps = ["Artifacts", "Libdl", "MbedTLS_jll"]
uuid = "29816b5a-b9ab-546f-933c-edad1886dfa8"
version = "1.10.2+0"

[[Libdl]]
uuid = "8f399da3-3557-5675-b5ff-fb832c97cbdb"

[[LinearAlgebra]]
deps = ["Libdl", "libblastrampoline_jll"]
uuid = "37e2e46d-f89d-539d-b4ee-838fcccc9c8e"

[[Logging]]
uuid = "56ddb016-857b-54e1-b83d-db4d58db5568"

[[Markdown]]
deps = ["Base64"]
uuid = "d6f4376e-aef5-505a-96c1-9c027394607a"

[[MbedTLS_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "c8ffd9c3-330d-5841-b78e-0817d7145fa1"
version = "2.28.0+0"

[[Mmap]]
uuid = "a63ad114-7e13-5084-954f-fe012c677804"

[[MozillaCACerts_jll]]
uuid = "14a3606d-f60d-562e-9121-12d972cd8159"
version = "2022.2.1"

[[NetworkOptions]]
uuid = "ca575930-c2e3-43a9-ace4-1e988b2c1908"
version = "1.2.0"

[[OpenBLAS_jll]]
deps = ["Artifacts", "CompilerSupportLibraries_jll", "Libdl"]
uuid = "4536629a-c528-5b80-bd46-f80d51c5b363"
version = "0.3.20+0"

[[Parsers]]
deps = ["Dates"]
git-tree-sha1 = "3d5bf43e3e8b412656404ed9466f1dcbf7c50269"
uuid = "69de0a69-1ddd-5017-9359-2bf0b02dc9f0"
version = "2.4.0"

[[Pkg]]
deps = ["Artifacts", "Dates", "Downloads", "LibGit2", "Libdl", "Logging", "Markdown", "Printf", "REPL", "Random", "SHA", "Serialization", "TOML", "Tar", "UUIDs", "p7zip_jll"]
uuid = "44cfe95a-1eb2-52ea-b672-e2afdf69b78f"
version = "1.8.0"

[[PlutoUI]]
deps = ["AbstractPlutoDingetjes", "Base64", "ColorTypes", "Dates", "Hyperscript", "HypertextLiteral", "IOCapture", "InteractiveUtils", "JSON", "Logging", "Markdown", "Random", "Reexport", "UUIDs"]
git-tree-sha1 = "8d1f54886b9037091edf146b517989fc4a09efec"
uuid = "7f904dfe-b85e-4ff6-b463-dae2292396a8"
version = "0.7.39"

[[Printf]]
deps = ["Unicode"]
uuid = "de0858da-6303-5e67-8744-51eddeeeb8d7"

[[REPL]]
deps = ["InteractiveUtils", "Markdown", "Sockets", "Unicode"]
uuid = "3fa0cd96-eef1-5676-8a61-b3b8758bbffb"

[[Random]]
deps = ["SHA", "Serialization"]
uuid = "9a3f8284-a2c9-5f02-9a11-845980a1fd5c"

[[Reexport]]
git-tree-sha1 = "45e428421666073eab6f2da5c9d310d99bb12f9b"
uuid = "189a3867-3050-52da-a836-e630ba90ab69"
version = "1.2.2"

[[SHA]]
uuid = "ea8e919c-243c-51af-8825-aaa63cd721ce"
version = "0.7.0"

[[Serialization]]
uuid = "9e88b42a-f829-5b0c-bbe9-9e923198166b"

[[Sockets]]
uuid = "6462fe0b-24de-5631-8697-dd941f90decc"

[[SparseArrays]]
deps = ["LinearAlgebra", "Random"]
uuid = "2f01184e-e22b-5df5-ae63-d93ebab69eaf"

[[Statistics]]
deps = ["LinearAlgebra", "SparseArrays"]
uuid = "10745b16-79ce-11e8-11f9-7d13ad32a3b2"

[[TOML]]
deps = ["Dates"]
uuid = "fa267f1f-6049-4f14-aa54-33bafae1ed76"
version = "1.0.0"

[[Tar]]
deps = ["ArgTools", "SHA"]
uuid = "a4e569a6-e804-4fa4-b0f3-eef7a1d5b13e"
version = "1.10.0"

[[Test]]
deps = ["InteractiveUtils", "Logging", "Random", "Serialization"]
uuid = "8dfed614-e22c-5e08-85e1-65c5234f0b40"

[[Tricks]]
git-tree-sha1 = "6bac775f2d42a611cdfcd1fb217ee719630c4175"
uuid = "410a4b4d-49e4-4fbc-ab6d-cb71b17b3775"
version = "0.1.6"

[[UUIDs]]
deps = ["Random", "SHA"]
uuid = "cf7118a7-6976-5b1a-9a39-7adc72f591a4"

[[Unicode]]
uuid = "4ec0a83e-493e-50e2-b9ac-8f72acf5a8f5"

[[Zlib_jll]]
deps = ["Libdl"]
uuid = "83775a58-1f1d-513f-b197-d71354ab007a"
version = "1.2.12+3"

[[libblastrampoline_jll]]
deps = ["Artifacts", "Libdl", "OpenBLAS_jll"]
uuid = "8e850b90-86db-534c-a0d3-1478176c7d93"
version = "5.1.1+0"

[[nghttp2_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "8e850ede-7688-5339-a07c-302acd2aaf8d"
version = "1.48.0+0"

[[p7zip_jll]]
deps = ["Artifacts", "Libdl"]
uuid = "3f19e933-33d8-53b3-aaab-bd5110c3b7a0"
version = "17.4.0+0"
"""

# â•”â•â•¡ Cell order:
# â•Ÿâ”€15f5c31a-8aef-11eb-3f19-cf0a4e456e7a
# â•Ÿâ”€5dd2329a-8aef-11eb-23a9-7f3c325bcf74
# â• â•7490def0-8aef-11eb-19ce-4b11ce5a9328
# â• â•675e66aa-8aef-11eb-27be-5fe273e33297
# â•Ÿâ”€800d827e-8c20-11eb-136a-97a622a7c1e6
# â•Ÿâ”€9a24985a-8aef-11eb-104a-bd9abf0adc6d
# â•Ÿâ”€a2fad250-8aef-11eb-200f-e5f8caa57a67
# â• â•abb45d6a-8aef-11eb-37a4-7b10847b39b4
# â• â•bff99828-8aef-11eb-107b-a5c67101c735
# â•Ÿâ”€cdde6fe8-8aef-11eb-0a3c-77e28f7a2c09
# â•Ÿâ”€f58d428c-8aef-11eb-3127-89d729e23823
# â• â•b73605ca-8ee4-11eb-1a0d-bb6678de91c6
# â•Ÿâ”€c6da4248-8c19-11eb-1c16-093695add9a9
# â• â•ffca4c72-8aef-11eb-07ac-6d5c58715a71
# â•Ÿâ”€d4c67b82-8c1a-11eb-302f-b79c86412ce5
# â• â•e71e4798-8ee4-11eb-3ea2-fdbbcdcf7410
# â•Ÿâ”€0f2ac53c-8c1b-11eb-3841-27f4ea1e9617
# â•Ÿâ”€12f1228a-8af0-11eb-0449-230ae20bfa7a
# â• â•18e8e4b6-8af0-11eb-2f17-2726f162e9b0
# â• â•1f38f8c6-8ee5-11eb-1c01-f3706534a9cf
# â•Ÿâ”€3a1efd5a-8af0-11eb-21a2-d1011f16555c
# â• â•3fae31a0-8af0-11eb-1ea8-7980e7875039
# â•Ÿâ”€5b10a2b6-8af0-11eb-3fe7-4b78b4c22550
# â• â•6061dc94-8af0-11eb-215a-4f3af731774e
# â•Ÿâ”€624eae74-8af0-11eb-025b-8b68dc55f31e
# â• â•d4c8c38c-8ee6-11eb-0b49-33fbfbd214f3
# â•Ÿâ”€7b979410-8af0-11eb-299c-af0a5d740c24
# â•Ÿâ”€8802ff60-8af0-11eb-21ac-b9fdbeac7c24
# â• â•a36582d4-8af0-11eb-2b5a-e577c5ed07e2
# â• â•a74a9966-8af0-11eb-350f-6787d2759eba
# â•Ÿâ”€ae9ee028-8af0-11eb-10c0-6f2db3ab8025
# â•Ÿâ”€b73b5eaa-8af0-11eb-191f-cd15de19bc38
# â•Ÿâ”€c0c757b2-8af0-11eb-38f1-3bc3ec4c43bc
# â• â•c5472fb0-8af0-11eb-04f1-95a1f7b6b9e0
# â•Ÿâ”€ce0e65d4-8af0-11eb-0c86-2105c26b62eb
# â• â•d376016a-8af0-11eb-3a15-4322759143d1
# â•Ÿâ”€d70c56bc-8af0-11eb-1220-09e78dba26f7
# â• â•dc24f5a0-8af0-11eb-0332-2bc0834d426c
# â•Ÿâ”€e3c136de-8af0-11eb-06f1-9393c0f95fbb
# â• â•e836dac8-8af0-11eb-1865-e3feeb011fc4
# â•Ÿâ”€ecfd04e4-8af0-11eb-0962-f548d2eabad3
# â• â•f0e24b50-8af0-11eb-1a0e-5d925f3743e0
# â• â•11c500e8-8ee2-11eb-3291-4382b60c5a2b
# â•Ÿâ”€22512ab2-8af1-11eb-260b-8d6c16762547
# â• â•2a7c1fc6-8af1-11eb-2909-554597aa2949
# â•Ÿâ”€2e3304fe-8af1-11eb-0f6a-0f84d58326bf
# â• â•33350038-8af1-11eb-1ff5-6d42d86491a3
# â•Ÿâ”€3713a8da-8af1-11eb-2cb2-1957455227d0
# â• â•59f58f1c-8af1-11eb-2e88-997e9d4bcc48
# â•Ÿâ”€5c86e276-8af1-11eb-2b2e-3386e6795f37
# â• â•61ee9ace-8af1-11eb-34bd-c5af962c8d82
# â•Ÿâ”€6849d9ec-8af1-11eb-06d6-db49af4796bc
# â• â•6ba266f4-8af1-11eb-10a3-3daf6e473142
# â•Ÿâ”€74a3ddb4-8af1-11eb-186e-4d80402adfcf
# â• â•7a88c4ba-8af1-11eb-242c-a1813a9e6741
# â•Ÿâ”€7d3fcbd6-8af1-11eb-0441-2f88a9d59966
# â• â•84c0d56a-8af1-11eb-30f3-d137b377c31f
# â•Ÿâ”€8c2ed15a-8af1-11eb-2e96-1df34510e773
# â• â•94182f88-8af1-11eb-207a-37083c1ead68
# â• â•a0286cdc-8af1-11eb-050e-072acdd4f0a0
# â•Ÿâ”€aa3931fc-8af1-11eb-2f42-f582b8e639ad
# â• â•c01bf4b6-8af1-11eb-2f17-bfe0c93d48f9
# â•Ÿâ”€c80e05ba-8af1-11eb-20fc-235b45f2eb4b
# â• â•cc99d9ce-8af1-11eb-12ec-fbd6df3becc8
# â•Ÿâ”€e3931226-8af1-11eb-0da5-fb3c1c22d12e
# â• â•e793e300-8af1-11eb-2c89-e7bc1be249f0
# â• â•e8d2ec8e-8af1-11eb-2018-1fa4df5b47ad
# â•Ÿâ”€f0a4cb58-8af1-11eb-054c-03192285b5e2
# â•Ÿâ”€f5c28c92-8af1-11eb-318f-5fa059d8fd80
# â• â•fc2d2f1a-8af1-11eb-11a4-8700f94e866e
# â•Ÿâ”€007cd39a-8af2-11eb-053d-f584d68f7d2f
# â• â•72fbb3ec-8ee8-11eb-3836-11092ef74e86
# â• â•054d848a-8af2-11eb-1f98-67f5d0b9f4ec
# â•Ÿâ”€0dfc5054-8af2-11eb-098d-35f4e69ae544
# â• â•126300a2-8af2-11eb-00ea-e76a979aef45
# â• â•14e46866-8af2-11eb-0894-bba824f266f0
# â•Ÿâ”€1e7edfdc-8af2-11eb-1429-4d4220bad0f0
# â• â•25a47c54-8af2-11eb-270a-5b58c3aafe6e
# â•Ÿâ”€2dc4f936-8af2-11eb-1117-9bc10e619ec6
# â• â•76a4e83c-8af2-11eb-16d7-75eaabcb21b6
# â•Ÿâ”€797264de-8af2-11eb-0cb0-adf3fbc95c90
# â•Ÿâ”€80179748-8af2-11eb-0910-2b825104159d
# â• â•36b723fc-8ee9-11eb-1b92-451b992acc0c
# â• â•37cd1f1c-8ee9-11eb-015c-ade9efc27708
# â•Ÿâ”€8af63980-8af2-11eb-3028-83a935bac0db
# â• â•50ab0cf6-8ee9-11eb-3e04-af5fef7f2850
# â• â•93af6754-8af2-11eb-0fe6-216d76e683de
# â•Ÿâ”€a105bd68-8af2-11eb-31f6-3335b4fb0f08
# â• â•a843a0c2-8af2-11eb-2435-17e2c36ec253
# â• â•b4d9cbb8-8af2-11eb-247c-d5b16e0de13f
# â•Ÿâ”€bc0a2f22-8af2-11eb-3803-f54f84ddfc46
# â• â•f0bc1fdc-8ee9-11eb-2916-d71e1cf36375
# â•Ÿâ”€36a2872e-8eeb-11eb-0999-4153ced71678
# â• â•9ca70cfc-8eeb-11eb-361b-b929089ca109
# â• â•d4a43094-8eeb-11eb-106f-3b54253aa663
# â•Ÿâ”€270950ac-8eed-11eb-365d-df9d36d090bc
# â•Ÿâ”€c36dc5f8-8af2-11eb-3f35-fb86143a54d2
# â• â•c96f7f50-8af2-11eb-0513-d538cf6bc619
# â• â•cf90c600-8af2-11eb-262a-2763ae29b428
# â•Ÿâ”€d53422a0-8af2-11eb-0417-b9740c4a571c
# â• â•dc5b9bbc-8af2-11eb-0197-9b5da5087f0d
# â•Ÿâ”€e735a302-8af2-11eb-2ce7-01435b60fdd9
# â• â•eb158e60-8af2-11eb-2227-59d6404e3335
# â• â•ee579dca-8af2-11eb-140f-a96778b7b39f
# â•Ÿâ”€f969eed2-8af2-11eb-1e78-5b322a7f4ebd
# â•Ÿâ”€72e1b146-8c1c-11eb-2c56-b1342271c2f6
# â• â•7732b6d8-8dab-11eb-0bc2-19690386ec27
# â• â•29463b02-8dab-11eb-0bf5-23a3f4075b32
# â•Ÿâ”€a5d93434-8dac-11eb-34bf-91061089f0ef
# â•Ÿâ”€0b6d234e-8af3-11eb-1ba9-a1dcf1497785
# â•Ÿâ”€119d269c-8af3-11eb-1fdc-b7ac75b89cf2
# â• â•1886f60e-8af3-11eb-2117-eb0014d2fca1
# â• â•1a0e2998-8af3-11eb-031b-a3448fd65041
# â• â•1ecf434a-8af3-11eb-3c49-cb21c6a80bfc
# â• â•2192c228-8af3-11eb-19d8-81db4f3c0d81
# â•Ÿâ”€2d0bb0a6-8af3-11eb-384d-29fbb0f66f24
# â• â•316e5074-8af3-11eb-256b-c5b212f7e0d3
# â• â•39a85a58-8af3-11eb-1334-6f50ed9acd31
# â•Ÿâ”€3e83981a-8af3-11eb-3c87-77797adb7e1f
# â• â•3e1c4090-8af3-11eb-33d0-b9c299fef20d
# â• â•4be905b4-8af3-11eb-0344-dbdc7e94ddf3
# â•Ÿâ”€4e8f6cb8-8af3-11eb-1746-9384995d7022
# â•Ÿâ”€54d2a5b8-8af3-11eb-3273-85d551fceb7b
# â•Ÿâ”€00000000-0000-0000-0000-000000000001
# â•Ÿâ”€00000000-0000-0000-0000-000000000002
